{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Model Saving Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the notebook environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "from utils import *\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/raw_training_data.mat')\n",
    "data_glove_1 = raw['train_dg'][0][0]\n",
    "data_glove_1_train = np.delete(data_glove_1, 3, 1)\n",
    "data_glove_2 = raw['train_dg'][1][0]\n",
    "data_glove_2_train = np.delete(data_glove_2, 3, 1)\n",
    "data_glove_3 = raw['train_dg'][2][0]\n",
    "data_glove_3_train = np.delete(data_glove_3, 3, 1)\n",
    "\n",
    "ecog_1_train = raw['train_ecog'][0][0]\n",
    "ecog_2_train = raw['train_ecog'][1][0]\n",
    "ecog_3_train = raw['train_ecog'][2][0]\n",
    "\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub1_comp.mat')\n",
    "ecog_1_comp = raw['train_data']\n",
    "dg_1_comp = raw['train_dg']\n",
    "ecog_1_valid = raw['test_data'][49000:]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub2_comp.mat')\n",
    "ecog_2_comp = raw['train_data']\n",
    "dg_2_comp = raw['train_dg']\n",
    "ecog_2_valid = raw['test_data'][49000:]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub3_comp.mat')\n",
    "ecog_3_comp = raw['train_data']\n",
    "dg_3_comp = raw['train_dg']\n",
    "ecog_3_valid = raw['test_data'][49000:]\n",
    "\n",
    "dg_1_raw = scipy.io.loadmat('./datasets/sub1_testlabels.mat')\n",
    "dg_1_valid = dg_1_raw['test_dg'][49000:]\n",
    "dg_1_valid = np.delete(dg_1_valid, 3, 1)\n",
    "\n",
    "dg_2_raw = scipy.io.loadmat('./datasets/sub2_testlabels.mat')\n",
    "dg_2_valid = dg_2_raw['test_dg'][49000:]\n",
    "dg_2_valid = np.delete(dg_2_valid, 3, 1)\n",
    "\n",
    "dg_3_raw = scipy.io.loadmat('./datasets/sub3_testlabels.mat')\n",
    "dg_3_valid = dg_3_raw['test_dg'][49000:]\n",
    "dg_3_valid = np.delete(dg_3_valid, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute features and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 62, using nperseg = 62\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615,)\n",
      "For Subject 1\n",
      "For XGBoost: ([0.5697004646300975, 0.7127210821071518, 0.19972146484178074, 0.3181432431150917], 0.4500715636735304)\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_1_train, 1000, winLen, winOverlap)\n",
    "# R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_1_valid, 1000, winLen, winOverlap)\n",
    "# R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_1_train\n",
    "Y_test = dg_1_valid\n",
    "Y_train = sig.resample(Y_train, feature_train.shape[0], axis=0)\n",
    "Y_test = sig.resample(Y_test, feature_test.shape[0], axis=0)\n",
    "\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "idx_1 = feature_selection(R_train, Y_train, 800)\n",
    "print(idx_1.shape)\n",
    "\n",
    "R_train = R_train[:, idx_1]\n",
    "R_test = R_test[:, idx_1]\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "prediction_XGB_1 = xgb_reg.predict(R_test)\n",
    "\n",
    "print('For Subject 1')\n",
    "print(f'For XGBoost: {correlation(prediction_XGB_1, Y_test)}')\n",
    "\n",
    "xgb_reg.save_model('./models/XGB_S1.json')\n",
    "np.save('./models/idx_S1.npy', idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Subject 1\n",
      "For LightGBM: ([0.6193401464499385, 0.75773013227357, 0.287864758762844, 0.3264518893794178], 0.49784673171644256)\n",
      "For ensemble: ([0.6075949935248183, 0.7485007880768504, 0.2720162168539936, 0.3353982537734647], 0.49087756305728175)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_reg_list = [LGBMRegressor(n_estimators=1000, max_depth=20, learning_rate=0.01) for _ in range(4)]\n",
    "\n",
    "for i in range(4):\n",
    "    lgbm_reg_list[i].fit(R_train, Y_train[:,i])\n",
    "    lgbm_reg_list[i].booster_.save_model(f'./models/lgbr_f{i}_S1.txt')\n",
    "\n",
    "prediction_lgbm_list = [lgbm_reg.predict(R_test) for lgbm_reg in lgbm_reg_list]\n",
    "prediction_lgbm_1 = np.vstack(prediction_lgbm_list).T\n",
    "print('For Subject 1')\n",
    "print(f'For LightGBM: {correlation(prediction_lgbm_1, Y_test)}')\n",
    "\n",
    "prediction_ensemble = (prediction_XGB_1 + prediction_lgbm_1) / 2\n",
    "print(f'For ensemble: {correlation(prediction_ensemble, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5999, 549)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "\n",
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_2_train, 1000, winLen, winOverlap)\n",
    "# R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_2_valid, 1000, winLen, winOverlap)\n",
    "# R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_2_train\n",
    "Y_test = dg_2_valid\n",
    "Y_train = sig.resample(Y_train, feature_train.shape[0], axis=0)\n",
    "Y_test = sig.resample(Y_test, feature_test.shape[0], axis=0)\n",
    "\n",
    "\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "idx_2 = feature_selection(R_train, Y_train, 800)\n",
    "print(idx_2.shape)\n",
    "\n",
    "R_train = R_train[:, idx_2]\n",
    "R_test = R_test[:, idx_2]\n",
    "\n",
    "R_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Subject 2\n",
      "For XGBoost: ([0.5933382893119988, 0.3820826422678676, 0.2489812591320926, 0.2591780080679073], 0.3708950496949666)\n"
     ]
    }
   ],
   "source": [
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "print('For Subject 2')\n",
    "print(f'For XGBoost: {correlation(prediction_XGB, Y_test)}')\n",
    "\n",
    "xgb_reg.save_model('./models/XGB_S2.json')\n",
    "np.save('./models/idx_S2.npy', idx_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Subject 2\n",
      "For LightGBM: ([0.6120384671957414, 0.4291699576228054, 0.27032010324418687, 0.2653151439637098], 0.39421091800661084)\n",
      "For ensemble: ([0.6117157991861485, 0.4225477384405255, 0.26798196146776515, 0.27458809744134943], 0.3942083991339472)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_reg_list = [LGBMRegressor(n_estimators=1000, max_depth=20, learning_rate=0.01) for _ in range(4)]\n",
    "\n",
    "for i in range(4):\n",
    "    lgbm_reg_list[i].fit(R_train, Y_train[:,i])\n",
    "    lgbm_reg_list[i].booster_.save_model(f'./models/lgbr_f{i}_S2.txt')\n",
    "\n",
    "prediction_lgbm_list = [lgbm_reg.predict(R_test) for lgbm_reg in lgbm_reg_list]\n",
    "prediction_lgbm_2 = np.vstack(prediction_lgbm_list).T\n",
    "print('For Subject 2')\n",
    "print(f'For LightGBM: {correlation(prediction_lgbm_2, Y_test)}')\n",
    "\n",
    "prediction_ensemble = (prediction_XGB + prediction_lgbm_2) / 2\n",
    "print(f'For ensemble: {correlation(prediction_ensemble, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599,)\n",
      "For Subject 3\n",
      "For XGBoost: ([0.7752297742295375, 0.6422236814131032, 0.6144125437786533, 0.6950473981200583], 0.6817283493853381)\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_3_train, 1000, winLen, winOverlap)\n",
    "# R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_3_valid, 1000, winLen, winOverlap)\n",
    "# R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_3_train\n",
    "Y_test = dg_3_valid\n",
    "Y_train = sig.resample(Y_train, feature_train.shape[0], axis=0)\n",
    "Y_test = sig.resample(Y_test, feature_test.shape[0], axis=0)\n",
    "\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "idx_3 = feature_selection(R_train, Y_train, 800)\n",
    "print(idx_3.shape)\n",
    "\n",
    "R_train = R_train[:, idx_3]\n",
    "R_test = R_test[:, idx_3]\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "print('For Subject 3')\n",
    "print(f'For XGBoost: {correlation(prediction_XGB, Y_test)}')\n",
    "\n",
    "xgb_reg.save_model('./models/XGB_S3.json')\n",
    "np.save('./models/idx_S3.npy', idx_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Subject 3\n",
      "For LightGBM: ([0.7834503219536425, 0.6847308209774405, 0.6244810779215075, 0.7405856810291012], 0.7083119754704228)\n",
      "For ensemble: ([0.7846392928883842, 0.6753867365057135, 0.6246371602515357, 0.7307276577612088], 0.7038477118517106)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_reg_list = [LGBMRegressor(n_estimators=1000, max_depth=20, learning_rate=0.01) for _ in range(4)]\n",
    "\n",
    "for i in range(4):\n",
    "    lgbm_reg_list[i].fit(R_train, Y_train[:,i])\n",
    "    lgbm_reg_list[i].booster_.save_model(f'./models/lgbr_f{i}_S3.txt')\n",
    "\n",
    "prediction_lgbm_list = [lgbm_reg.predict(R_test) for lgbm_reg in lgbm_reg_list]\n",
    "prediction_lgbm_3 = np.vstack(prediction_lgbm_list).T\n",
    "print('For Subject 3')\n",
    "print(f'For LightGBM: {correlation(prediction_lgbm_3, Y_test)}')\n",
    "\n",
    "prediction_ensemble = (prediction_XGB + prediction_lgbm_3) / 2\n",
    "print(f'For ensemble: {correlation(prediction_ensemble, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 62, using nperseg = 62\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "ecog_1_leaderboard = ecog_1_comp[500: 500 + 147500]\n",
    "dg_1_leaderboard = dg_1_comp[500: 500 + 147500]\n",
    "\n",
    "ecog_2_leaderboard = ecog_2_comp[500: 500 + 147500]\n",
    "dg_2_leaderboard = dg_2_comp[500: 500 + 147500]\n",
    "\n",
    "ecog_3_leaderboard = ecog_3_comp[500: 500 + 147500]\n",
    "dg_3_leaderboard = dg_3_comp[500: 500 + 147500]\n",
    "\n",
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "\n",
    "\n",
    "feature_1 = get_windowed_feats(ecog_1_leaderboard, 1000, winLen, winOverlap)\n",
    "# R_1 = create_R_matrix(feature_1, 5)\n",
    "feature_2 = get_windowed_feats(ecog_2_leaderboard, 1000, winLen, winOverlap)\n",
    "# R_2 = create_R_matrix(feature_2, 5)\n",
    "feature_3 = get_windowed_feats(ecog_3_leaderboard, 1000, winLen, winOverlap)\n",
    "# R_3 = create_R_matrix(feature_3, 5)\n",
    "\n",
    "idx_1 = np.load('./models/idx_S1.npy')\n",
    "idx_2 = np.load('./models/idx_S2.npy')\n",
    "idx_3 = np.load('./models/idx_S3.npy')\n",
    "\n",
    "R_1 = create_R_matrix(feature_1, 20)[:, idx_1]\n",
    "R_2 = create_R_matrix(feature_2, 20)[:, idx_2]\n",
    "R_3 = create_R_matrix(feature_3, 20)[:, idx_3]\n",
    "\n",
    "R_list = [R_1, R_2, R_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "predictions = []\n",
    "for i in range(3):\n",
    "    # Load XGB\n",
    "    xgb_reg = xgb.XGBRegressor()\n",
    "    xgb_reg.load_model(f\"./models/XGB_S{i + 1}.json\")\n",
    "\n",
    "    prediction_xgb = xgb_reg.predict(R_list[i])\n",
    "    \n",
    "    # Load LGBM\n",
    "    lgbm_reg_list = [lightgbm.Booster(model_file=f'./models/lgbr_f{j}_S{i + 1}.txt') for j in range(4)]\n",
    "    \n",
    "    prediction_lgbm_list = [lgbm_reg.predict(R_list[i]) for lgbm_reg in lgbm_reg_list]\n",
    "    prediction_lgbm = np.vstack(prediction_lgbm_list).T\n",
    "    \n",
    "    \n",
    "    prediction = prediction_lgbm\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Subject 1\n",
      "For XGBoost: ([0.5907641612580329, 0.7977617513623582, 0.4600879272260482, 0.3639373927544931], 0.5531378081502332)\n",
      "For Subject 2\n",
      "For XGBoost: ([0.6507526931463948, 0.5608567789524364, 0.5487816884251456, 0.35826305816146226], 0.5296635546713598)\n",
      "For Subject 3\n",
      "For XGBoost: ([0.7403539510044402, 0.7341086861577378, 0.6143714085152925, 0.5589147654194959], 0.6619372027742416)\n"
     ]
    }
   ],
   "source": [
    "print('For Subject 1')\n",
    "print(f'For XGBoost: {correlation(sig.resample(predictions[0], dg_1_leaderboard.shape[0]), dg_1_leaderboard)}')\n",
    "\n",
    "print('For Subject 2')\n",
    "print(f'For XGBoost: {correlation(sig.resample(predictions[1], dg_2_leaderboard.shape[0]), dg_2_leaderboard)}')\n",
    "\n",
    "print('For Subject 3')\n",
    "print(f'For XGBoost: {correlation(sig.resample(predictions[2], dg_3_leaderboard.shape[0]), dg_3_leaderboard)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./leaderboard_prediction.mat')\n",
    "raw['predicted_dg'].shape\n",
    "prediction_1 = raw['predicted_dg'][2][0]\n",
    "prediction_1 = np.delete(prediction_1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.728168426187513,\n",
       "  0.723727685575862,\n",
       "  0.5954600848958687,\n",
       "  0.5552881706938677],\n",
       " 0.6506610918382778)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction_1, dg_3_leaderboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
