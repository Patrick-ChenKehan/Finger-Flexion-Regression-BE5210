{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Model Saving Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the notebook environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/raw_training_data.mat')\n",
    "data_glove_1 = raw['train_dg'][0][0]\n",
    "data_glove_1 = np.delete(data_glove_1, 3, 1)\n",
    "data_glove_2 = raw['train_dg'][1][0]\n",
    "data_glove_2 = np.delete(data_glove_2, 3, 1)\n",
    "data_glove_3 = raw['train_dg'][2][0]\n",
    "data_glove_3 = np.delete(data_glove_3, 3, 1)\n",
    "\n",
    "ecog_1 = raw['train_ecog'][0][0]\n",
    "ecog_2 = raw['train_ecog'][1][0]\n",
    "ecog_3 = raw['train_ecog'][2][0]\n",
    "\n",
    "labels_1 = np.argmax(data_glove_1, axis=1)\n",
    "labels_2 = np.argmax(data_glove_2, axis=1)\n",
    "labels_3 = np.argmax(data_glove_3, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(raw_eeg, fs=1000):\n",
    "    \"\"\"\n",
    "    Write a filter function to clean underlying data.\n",
    "    Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
    "    Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
    "    distorting the underlying data!\n",
    "\n",
    "    Input: \n",
    "        raw_eeg (samples x channels): the raw signal\n",
    "        fs: the sampling rate (1000 for this dataset)\n",
    "    Output: \n",
    "        clean_data (samples x channels): the filtered signal\n",
    "    \"\"\"\n",
    "    dim = 100\n",
    "    # b = sig.firwin(numtaps=dim + 1, cutoff=[0.15, 200], pass_zero='bandpass', fs=fs)\n",
    "    b, a = sig.butter(N=2, Wn=[0.15, 200], btype='bandpass', fs=fs, output='ba')\n",
    "    filtered_eeg = sig.filtfilt(b, a, x=raw_eeg, axis=0)\n",
    "    \n",
    "    return filtered_eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train test split and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before splitting: 300000 samples\n",
      "After splitting: 210000 training samples and 90000 testing samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_ratio = 0.7\n",
    "\n",
    "ecog_1_train = ecog_1[:int(train_test_ratio * ecog_1.shape[0])]\n",
    "ecog_1_test = ecog_1[int(train_test_ratio * ecog_1.shape[0]):]\n",
    "data_glove_1_train = data_glove_1[:int(train_test_ratio * data_glove_1.shape[0])]\n",
    "data_glove_1_test = data_glove_1[int(train_test_ratio * data_glove_1.shape[0]):]\n",
    "\n",
    "ecog_2_train = ecog_2[:int(train_test_ratio * ecog_2.shape[0])]\n",
    "ecog_2_test = ecog_2[int(train_test_ratio * ecog_2.shape[0]):]\n",
    "data_glove_2_train = data_glove_2[:int(train_test_ratio * data_glove_2.shape[0])]\n",
    "data_glove_2_test = data_glove_2[int(train_test_ratio * data_glove_2.shape[0]):]\n",
    "\n",
    "ecog_3_train = ecog_3[:int(train_test_ratio * ecog_3.shape[0])]\n",
    "ecog_3_test = ecog_3[int(train_test_ratio * ecog_3.shape[0]):]\n",
    "data_glove_3_train = data_glove_3[:int(train_test_ratio * data_glove_3.shape[0])]\n",
    "data_glove_3_test = data_glove_3[int(train_test_ratio * data_glove_3.shape[0]):]\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "Before splitting: {ecog_1.shape[0]} samples\n",
    "After splitting: {ecog_1_train.shape[0]} training samples and {ecog_1_test.shape[0]} testing samples\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NumWins(x, fs, winLen, winDisp):\n",
    "    return int(1 + (x.shape[0] - winLen * fs) / (winDisp * fs))\n",
    "\n",
    "winLen = 200 / 1e3\n",
    "winOverlap = 40 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "NumWins(ecog_1, 1000, winLen, winDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LineLength(x):\n",
    "    return np.abs(np.diff(x, axis=0)).sum(axis=0)\n",
    "\n",
    "def Area(x):\n",
    "    return np.abs(x).sum(axis=0)\n",
    "\n",
    "def Energy(x):\n",
    "    return (x ** 2).sum(axis=0)\n",
    "\n",
    "def ZeroCrossingMean(x):\n",
    "    return ((x < x.mean(axis=0))[1:] & (x[:-1] > x.mean(axis=0)) | (x > x.mean(axis=0))[1:] & (x[:-1] < x.mean(axis=0))).sum(axis=0)\n",
    "\n",
    "def numSpikes(x):\n",
    "    #TODO: implement\n",
    "    sig.find_peaks(x, height=0, distance=100)\n",
    "    pass\n",
    "\n",
    "def averageTimeDomain(x):\n",
    "    #TODO: implement\n",
    "    return np.mean(x, axis=0)\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    fs = 1000\n",
    "    # win = 4 * sf\n",
    "    freqs, psd = sig.welch(x, fs, axis=0, nperseg=x.shape[0])\n",
    "    \n",
    "    # Define delta lower and upper limits\n",
    "    # fmin, fmax = 0.5, 4\n",
    "\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "    \n",
    "    from scipy.integrate import simps\n",
    "\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    delta_power = simps(psd[idx_delta], dx=freq_res, axis=0)\n",
    "    \n",
    "    return delta_power\n",
    "\n",
    "def spectral_entropy(x, fs=1000):\n",
    "    # Calculate the power spectrum\n",
    "    f, Pxx = sig.welch(x, fs=fs)\n",
    "    # Normalize the power spectrum\n",
    "    Pxx_norm = Pxx / Pxx.sum()\n",
    "    # Calculate the spectral entropy\n",
    "    se = -1 * (Pxx_norm * np.log2(Pxx_norm)).sum()\n",
    "    return se\n",
    "\n",
    "def hjorth_complexity(x):\n",
    "    dx = np.diff(x)\n",
    "    d2x = np.diff(dx)\n",
    "    var_x = np.var(x)\n",
    "    var_dx = np.var(dx)\n",
    "    var_d2x = np.var(d2x)\n",
    "    activity = var_x\n",
    "    mobility = np.sqrt(var_d2x / var_dx)\n",
    "    # Calculate Hjorth complexity\n",
    "    complexity = mobility / activity\n",
    "    return complexity\n",
    "    \n",
    "# Kurtosis = @(x) ((1/size(x,1))*sum((x - mean(x)).^4))./(((1/size(x,1))*sum((x - mean(x)).^2)).^2);\n",
    "def Kurtosis(x):\n",
    "    return ((1/x.shape[0])*np.sum((x - np.mean(x))**4))/(((1/x.shape[0])*np.sum((x - np.mean(x))**2))**2)\n",
    "\n",
    "def Covariance(x):\n",
    "    convar = np.cov(x, rowvar=False)\n",
    "    feat = []\n",
    "    for i in range(convar.shape[0]):\n",
    "        feat += [convar[i, :i+1]]\n",
    "    return np.concatenate(feat)\n",
    "\n",
    "def get_features(filtered_window, fs=1000):\n",
    "    \"\"\"\n",
    "        Write a function that calculates features for a given filtered window. \n",
    "        Feel free to use features you have seen before in this class, features that\n",
    "        have been used in the literature, or design your own!\n",
    "\n",
    "        Input: \n",
    "        filtered_window (window_samples x channels): the window of the filtered ecog signal \n",
    "        fs: sampling rate\n",
    "        Output:\n",
    "        features (channels x num_features): the features calculated on each channel for the window\n",
    "    \"\"\"\n",
    "    feat_LL = LineLength(filtered_window)\n",
    "    feat_Area = Area(filtered_window)\n",
    "    feat_Energy = Energy(filtered_window)\n",
    "    feat_ZCM = ZeroCrossingMean(filtered_window)\n",
    "    feat_TimeAvg = averageTimeDomain(filtered_window)\n",
    "#     feat_SpectralEntropy = spectral_entropy(filtered_window)\n",
    "    feat_Hijorth = hjorth_complexity(filtered_window)\n",
    "    feat_kurtosis = Kurtosis(filtered_window)\n",
    "    feat_covariance = Covariance(filtered_window)\n",
    "    # feat_FreqAvg = averageFreqDomain(filtered_window)\n",
    "    \n",
    "    from pyriemann.estimation import Covariances\n",
    "    from pyriemann.tangentspace import TangentSpace\n",
    "    \n",
    "    # covar = Covariances().fit_transform(np.expand_dims(filtered_window.T, 0))\n",
    "    # # covest = Covariances('oas')\n",
    "    # # temp = np.expand_dims(filtered_window, axis=-1)\n",
    "    # # covar = covest.fit_transform(temp)\n",
    "    # ts = TangentSpace()\n",
    "    # tsfeat = ts.fit_transform(covar)\n",
    "    # # print(tsfeat.shape)\n",
    "\n",
    "    # raise notImplementedError()\n",
    "    return np.hstack([#feat_LL, \n",
    "                      #feat_Area, \n",
    "                      feat_Energy, \n",
    "                      #feat_ZCM, \n",
    "                      feat_TimeAvg, \n",
    "#                       feat_SpectralEntropy,\n",
    "                      feat_Hijorth,\n",
    "                      feat_kurtosis,\n",
    "                      feat_covariance,\n",
    "                      bandpower(filtered_window, 1000, 5, 15),\n",
    "                      bandpower(filtered_window, 1000, 20, 25),\n",
    "                      bandpower(filtered_window, 1000, 75, 115),\n",
    "                      bandpower(filtered_window, 1000, 125, 160),\n",
    "                      bandpower(filtered_window, 1000, 160, 175)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ecog_1[:500]\n",
    "Covariance(temp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
    "    \"\"\"\n",
    "        Write a function which processes data through the steps of filtering and\n",
    "        feature calculation and returns features. Points will be awarded for completing\n",
    "        each step appropriately (note that if one of the functions you call within this script\n",
    "        returns a bad output, you won't be double penalized). Note that you will need\n",
    "        to run the filter_data and get_features functions within this function. \n",
    "\n",
    "        Inputs:\n",
    "        raw_eeg (samples x channels): the raw signal\n",
    "        fs: the sampling rate (1000 for this dataset)\n",
    "        window_length: the window's length\n",
    "        window_overlap: the window's overlap\n",
    "        Output: \n",
    "        all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
    "            note that this is a 2D array. \n",
    "    \"\"\"\n",
    "    raw_ecog = filter_data(raw_ecog, fs)\n",
    "    \n",
    "    window_disp = window_length - window_overlap\n",
    "    \n",
    "    all_feats = np.vstack([get_features(raw_ecog[int(i * window_disp * fs):int(i * window_disp * fs + window_length * fs), :], fs) for i in range(NumWins(raw_ecog, fs, window_length, window_disp))])\n",
    "    \n",
    "    return all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_matrix(features, N_wind):\n",
    "    \"\"\" \n",
    "    Write a function to calculate the R matrix\n",
    "\n",
    "    Input:\n",
    "        features (samples (number of windows in the signal) x channels x features): \n",
    "        the features you calculated using get_windowed_feats\n",
    "        N_wind: number of windows to use in the R matrix\n",
    "\n",
    "    Output:\n",
    "        R (samples x (N_wind*channels*features))\n",
    "    \"\"\"\n",
    "    num_win = features.shape[0]\n",
    "    num_channel_features = features.shape[1]\n",
    "    \n",
    "    # Append a copy of the first N-1 rows to the beginning of features\n",
    "    features = np.vstack((features[:N_wind-1], features))\n",
    "    \n",
    "    R = np.zeros((num_win, N_wind * num_channel_features))\n",
    "    \n",
    "    for i in range(num_win):\n",
    "        # Get the feature matrix for the current window\n",
    "        # Resize the feature matrix and store in R\n",
    "        R[i,:] = features[i:i+N_wind,:].reshape(-1)\n",
    "\n",
    "    R = np.hstack((np.ones((R.shape[0], 1)), R))\n",
    "\n",
    "    return R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_windowed_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m winDisp \u001b[38;5;241m=\u001b[39m winLen \u001b[38;5;241m-\u001b[39m winOverlap\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Compute the R matrix for the training data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m feature_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_windowed_feats\u001b[49m(ecog_1_train, \u001b[38;5;241m1000\u001b[39m, winLen, winOverlap)\n\u001b[1;32m      7\u001b[0m R_train \u001b[38;5;241m=\u001b[39m create_R_matrix(feature_train, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      9\u001b[0m feature_test \u001b[38;5;241m=\u001b[39m get_windowed_feats(ecog_1_test, \u001b[38;5;241m1000\u001b[39m, winLen, winOverlap)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_windowed_feats' is not defined"
     ]
    }
   ],
   "source": [
    "winLen = 200 / 1e3\n",
    "winOverlap = 40 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "\n",
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_1_train, 1000, winLen, winOverlap)\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_1_test, 1000, winLen, winOverlap)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_1_train\n",
    "Y_test = data_glove_1_test\n",
    "Y_train = sig.resample(Y_train, R_train.shape[0], axis=0)\n",
    "Y_test = sig.resample(Y_test, R_test.shape[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre = np.corrcoef(R_train, Y_train, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(corre, copy=False, nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.unravel_index(np.argsort(corre[:-4, -4:].ravel())[-800:], corre[:, -4:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ = idx[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ = np.unique(idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corre[18927, -4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train_ = R_train[:,idx_]\n",
    "R_test_ = R_test[:, idx_]\n",
    "R_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weights\n",
    "# f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train)\n",
    "\n",
    "# prediction_LR = (R_test @ f_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# read data\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train_, Y_train)\n",
    "# make predictions\n",
    "prediction_XGB = xgb_reg.predict(R_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(prediction, target):\n",
    "    corr = [pearsonr(prediction[:,i], target[:,i]).statistic for i in range(4)]\n",
    "    return corr, np.mean(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Subject 1')\n",
    "# print(f'For linear regression: {correlation(prediction_LR, Y_test)}')\n",
    "print(f'For XGBoost: {correlation(prediction_XGB, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_2_train, 1000, winLen, winOverlap)\n",
    "R_train = create_R_matrix(feature_train, 3)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_2_test, 1000, winLen, winOverlap)\n",
    "R_test = create_R_matrix(feature_test, 3)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_2_train\n",
    "Y_test = data_glove_2_test\n",
    "Y_train = sig.resample(Y_train, R_train.shape[0], axis=0)\n",
    "Y_test = sig.resample(Y_test, R_test.shape[0], axis=0)\n",
    "\n",
    "# Compute the weights\n",
    "f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train)\n",
    "prediction_LR = (R_test @ f_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=200, max_depth=5, max_leaf_nodes=200)\n",
    "rf_reg.fit(R_train, Y_train)\n",
    "prediction_RF = rf_reg.predict(R_test)\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "\n",
    "print('For Subject 2')\n",
    "print(f'For linear regression: {[pearsonr(prediction_LR[:,i], Y_test[:,i]).statistic for i in range(4)]}')\n",
    "print(f'For random forest: {[pearsonr(prediction_RF[:,i], Y_test[:,i]).statistic for i in range(4)]}')\n",
    "print(f'For XGBoost: {[pearsonr(prediction_XGB[:,i], Y_test[:,i]).statistic for i in range(4)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Subject 3\n",
      "For linear regression: [0.515557634501014, 0.2753656952491606, 0.3861286395818362, 0.39087312864622037]\n",
      "For random forest: [0.7243048760525532, 0.5249419449942999, 0.6476626372046566, 0.42160591268365893]\n",
      "For XGBoost: [0.7026111184226042, 0.4022655712154394, 0.6120286981874062, 0.4094253084822335]\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_3_train, 1000, winLen, winOverlap)\n",
    "R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_3_test, 1000, winLen, winOverlap)\n",
    "R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_3_train\n",
    "Y_test = data_glove_3_test\n",
    "Y_train = sig.resample(Y_train, R_train.shape[0], axis=0)\n",
    "Y_test = sig.resample(Y_test, R_test.shape[0], axis=0)\n",
    "\n",
    "# Compute the weights\n",
    "f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train)\n",
    "prediction_LR = (R_test @ f_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, max_depth=5, max_leaf_nodes=200)\n",
    "rf_reg.fit(R_train, Y_train)\n",
    "prediction_RF = rf_reg.predict(R_test)\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "print('For Subject 3')\n",
    "print(f'For linear regression: {[pearsonr(prediction_LR[:,i], Y_test[:,i]).statistic for i in range(4)]}')\n",
    "print(f'For random forest: {[pearsonr(prediction_RF[:,i], Y_test[:,i]).statistic for i in range(4)]}')\n",
    "print(f'For XGBoost: {[pearsonr(prediction_XGB[:,i], Y_test[:,i]).statistic for i in range(4)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_1, 1000, winLen, winOverlap)\n",
    "R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_1\n",
    "Y_train = sig.resample(Y_train, R_train.shape[0], axis=0)\n",
    "\n",
    "# Compute the weights\n",
    "f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rf_reg = RandomForestRegressor(n_estimators=100, max_depth=5, max_leaf_nodes=200)\n",
    "# rf_reg.fit(R_train, Y_train)\n",
    "\n",
    "\n",
    "# np.save('./models/LR_Matrix_S1', f_train)\n",
    "# pickle.dump(rf_reg, open('./models/RF_Matrix_S1.pth', 'wb'))\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "# prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "\n",
    "xgb_reg.save_model('./models/XGB_S1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_2, 1000, winLen, winOverlap)\n",
    "R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_2\n",
    "Y_train = sig.resample(Y_train, R_train.shape[0], axis=0)\n",
    "\n",
    "# Compute the weights\n",
    "f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train)\n",
    "\n",
    "# from sklearn. ensemble import RandomForestRegressor\n",
    "# rf_reg = RandomForestRegressor(n_estimators=100, max_depth=5, max_leaf_nodes=200)\n",
    "# rf_reg.fit(R_train, Y_train)\n",
    "\n",
    "\n",
    "# np.save('./models/LR_Matrix_S2', f_train)\n",
    "# pickle.dump(rf_reg, open('./models/RF_Matrix_S2.pth', 'wb'))\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "# prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "\n",
    "xgb_reg.save_model('./models/XGB_S2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_3, 1000, winLen, winOverlap)\n",
    "R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_3\n",
    "Y_train = sig.resample(Y_train, R_train.shape[0], axis=0)\n",
    "\n",
    "# Compute the weights\n",
    "f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rf_reg = RandomForestRegressor(n_estimators=100, max_depth=5, max_leaf_nodes=200)\n",
    "# rf_reg.fit(R_train, Y_train)\n",
    "\n",
    "\n",
    "# np.save('./models/LR_Matrix_S3', f_train)\n",
    "# pickle.dump(rf_reg, open('./models/RF_Matrix_S3.pth', 'wb'))\n",
    "\n",
    "# create model instance\n",
    "xgb_reg = XGBRegressor(n_estimators=200, max_depth=5, learning_rate=0.01)\n",
    "# fit model\n",
    "xgb_reg.fit(R_train, Y_train)\n",
    "# make predictions\n",
    "# prediction_XGB = xgb_reg.predict(R_test)\n",
    "\n",
    "\n",
    "xgb_reg.save_model('./models/XGB_S3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 3521)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
