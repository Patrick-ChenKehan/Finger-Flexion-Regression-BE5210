{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the notebook environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/leaderboard_data.mat')\n",
    "ecog_1 = raw['leaderboard_ecog'][0][0]\n",
    "ecog_2 = raw['leaderboard_ecog'][1][0]\n",
    "ecog_3 = raw['leaderboard_ecog'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(raw_eeg, fs=1000):\n",
    "    \"\"\"\n",
    "    Write a filter function to clean underlying data.\n",
    "    Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
    "    Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
    "    distorting the underlying data!\n",
    "\n",
    "    Input: \n",
    "        raw_eeg (samples x channels): the raw signal\n",
    "        fs: the sampling rate (1000 for this dataset)\n",
    "    Output: \n",
    "        clean_data (samples x channels): the filtered signal\n",
    "    \"\"\"\n",
    "    dim = 100\n",
    "    b = sig.firwin(numtaps=dim + 1, cutoff=[0.15, 200], pass_zero='bandpass', fs=fs)\n",
    "\n",
    "    filtered_eeg = sig.filtfilt(b, 1, x=raw_eeg, axis=0)\n",
    "    \n",
    "    return filtered_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "def NumWins(x, fs, winLen, winDisp):\n",
    "    return int(1 + (x.shape[0] - winLen * fs) / (winDisp * fs))\n",
    "\n",
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "\n",
    "def LineLength(x):\n",
    "    return np.abs(np.diff(x, axis=0)).sum(axis=0)\n",
    "\n",
    "def Area(x):\n",
    "    return np.abs(x).sum(axis=0)\n",
    "\n",
    "def Energy(x):\n",
    "    return (x ** 2).sum(axis=0)\n",
    "\n",
    "def ZeroCrossingMean(x):\n",
    "    return ((x < x.mean(axis=0))[1:] & (x[:-1] > x.mean(axis=0)) | (x > x.mean(axis=0))[1:] & (x[:-1] < x.mean(axis=0))).sum(axis=0)\n",
    "\n",
    "def numSpikes(x):\n",
    "    #TODO: implement\n",
    "    sig.find_peaks(x, height=0, distance=100)\n",
    "    pass\n",
    "\n",
    "def averageTimeDomain(x):\n",
    "    #TODO: implement\n",
    "    return np.mean(x, axis=0)\n",
    "\n",
    "def averageFreqDomain(x):\n",
    "    #TODO: implement\n",
    "    fourier = np.fft.fft(x, axis=1)\n",
    "    N = len(fourier)\n",
    "    n = np.arange(N)\n",
    "    T = N/1000\n",
    "    freq = n/T \n",
    "    return [np.abs(fourier[(freq >= 8) & (freq <= 12)]).mean(axis=0), \n",
    "            np.abs(fourier[(freq >= 18) & (freq <= 24)]).mean(axis=0),\n",
    "            np.abs(fourier[(freq >= 75) & (freq <= 115)]).mean(axis=0),\n",
    "            np.abs(fourier[(freq >= 125) & (freq <= 159)]).mean(axis=0),\n",
    "            np.abs(fourier[(freq >= 159) & (freq <= 175)]).mean(axis=0)]\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    fs = 1000\n",
    "    # win = 4 * sf\n",
    "    freqs, psd = sig.welch(x, fs, axis=0, nperseg=x.shape[0])\n",
    "    \n",
    "    # Define delta lower and upper limits\n",
    "    # fmin, fmax = 0.5, 4\n",
    "\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "    \n",
    "    from scipy.integrate import simps\n",
    "\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    delta_power = simps(psd[idx_delta], dx=freq_res, axis=0)\n",
    "    \n",
    "    return delta_power\n",
    "    \n",
    "\n",
    "def get_features(filtered_window, fs=1000):\n",
    "    \"\"\"\n",
    "        Write a function that calculates features for a given filtered window. \n",
    "        Feel free to use features you have seen before in this class, features that\n",
    "        have been used in the literature, or design your own!\n",
    "\n",
    "        Input: \n",
    "        filtered_window (window_samples x channels): the window of the filtered ecog signal \n",
    "        fs: sampling rate\n",
    "        Output:\n",
    "        features (channels x num_features): the features calculated on each channel for the window\n",
    "    \"\"\"\n",
    "    feat_LL = LineLength(filtered_window)\n",
    "    feat_Area = Area(filtered_window)\n",
    "    feat_Energy = Energy(filtered_window)\n",
    "    feat_ZCM = ZeroCrossingMean(filtered_window)\n",
    "    feat_TimeAvg = averageTimeDomain(filtered_window)\n",
    "    feat_FreqAvg = averageFreqDomain(filtered_window)\n",
    "    \n",
    "    \n",
    "    return np.hstack([feat_LL, feat_Area, feat_Energy, feat_ZCM, \n",
    "                      feat_Energy,\n",
    "                      feat_TimeAvg, \n",
    "                      bandpower(filtered_window, 1000, 8, 12),\n",
    "                      bandpower(filtered_window, 1000, 18, 24),\n",
    "                      bandpower(filtered_window, 1000, 75, 115),\n",
    "                      bandpower(filtered_window, 1000, 125, 159),\n",
    "                      bandpower(filtered_window, 1000, 159, 175)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
    "    \"\"\"\n",
    "        Write a function which processes data through the steps of filtering and\n",
    "        feature calculation and returns features. Points will be awarded for completing\n",
    "        each step appropriately (note that if one of the functions you call within this script\n",
    "        returns a bad output, you won't be double penalized). Note that you will need\n",
    "        to run the filter_data and get_features functions within this function. \n",
    "\n",
    "        Inputs:\n",
    "        raw_eeg (samples x channels): the raw signal\n",
    "        fs: the sampling rate (1000 for this dataset)\n",
    "        window_length: the window's length\n",
    "        window_overlap: the window's overlap\n",
    "        Output: \n",
    "        all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
    "            note that this is a 2D array. \n",
    "    \"\"\"\n",
    "    raw_ecog = filter_data(raw_ecog, fs)\n",
    "    \n",
    "    window_disp = window_length - window_overlap\n",
    "    \n",
    "    all_feats = np.vstack([get_features(raw_ecog[int(i * window_disp * fs):int(i * window_disp * fs + window_length * fs), :], fs) for i in range(NumWins(raw_ecog, fs, window_length, window_overlap))])\n",
    "    \n",
    "    return all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_matrix(features, N_wind):\n",
    "    \"\"\" \n",
    "    Write a function to calculate the R matrix\n",
    "\n",
    "    Input:\n",
    "        features (samples (number of windows in the signal) x channels x features): \n",
    "        the features you calculated using get_windowed_feats\n",
    "        N_wind: number of windows to use in the R matrix\n",
    "\n",
    "    Output:\n",
    "        R (samples x (N_wind*channels*features))\n",
    "    \"\"\"\n",
    "    num_win = features.shape[0]\n",
    "    num_channel_features = features.shape[1]\n",
    "    \n",
    "    # Append a copy of the first N-1 rows to the beginning of features\n",
    "    features = np.vstack((features[:N_wind-1], features))\n",
    "    \n",
    "    R = np.zeros((num_win, N_wind * num_channel_features))\n",
    "    \n",
    "    for i in range(num_win):\n",
    "        # Get the feature matrix for the current window\n",
    "        # Resize the feature matrix and store in R\n",
    "        R[i,:] = features[i:i+N_wind,:].reshape(-1)\n",
    "\n",
    "    R = np.hstack((np.ones((R.shape[0], 1)), R))\n",
    "\n",
    "    return R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_submission(prediction_1, prediction_2, prediction_3):\n",
    "    prediction_1 = np.insert(np.repeat(prediction_1, 50, axis=0), -1, [prediction_1[-1]]*50 , axis=0)\n",
    "    prediction_2 = np.insert(np.repeat(prediction_2, 50, axis=0), -1, [prediction_2[-1]]*50 , axis=0)\n",
    "    prediction_3 = np.insert(np.repeat(prediction_3, 50, axis=0), -1, [prediction_3[-1]]*50 , axis=0)\n",
    "\n",
    "    prediction_1 = np.insert(prediction_1, 3, 0, axis=1)\n",
    "    prediction_2 = np.insert(prediction_2, 3, 0, axis=1)\n",
    "    prediction_3 = np.insert(prediction_3, 3, 0, axis=1)\n",
    "    \n",
    "    scipy.io.savemat('leaderboard_prediction.mat', {'predicted_dg': [[prediction_1], [prediction_2], [prediction_3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = get_windowed_feats(ecog_1, 1000, winLen, winOverlap)\n",
    "R_1 = create_R_matrix(feature_1, 5)\n",
    "feature_2 = get_windowed_feats(ecog_2, 1000, winLen, winOverlap)\n",
    "R_2 = create_R_matrix(feature_2, 5)\n",
    "feature_3 = get_windowed_feats(ecog_3, 1000, winLen, winOverlap)\n",
    "R_3 = create_R_matrix(feature_3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3411 features, but RandomForestRegressor is expecting 1861 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rf_reg_1 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./models/RF_Matrix_S1.pth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m prediction_1 \u001b[39m=\u001b[39m rf_reg_1\u001b[39m.\u001b[39;49mpredict(R_1)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    980\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    983\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    984\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3411 features, but RandomForestRegressor is expecting 1861 features as input."
     ]
    }
   ],
   "source": [
    "rf_reg_1 = pickle.load(open('./models/RF_Matrix_S1.pth', 'rb'))\n",
    "prediction_1 = rf_reg_1.predict(R_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_2 = pickle.load(open('./models/RF_Matrix_S2.pth', 'rb'))\n",
    "prediction_2 = rf_reg_2.predict(R_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_3 = pickle.load(open('./models/RF_Matrix_S3.pth', 'rb'))\n",
    "prediction_3 = rf_reg_3.predict(R_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_reg_1 = xgb.XGBRegressor()\n",
    "xgb_reg_1.load_model(\"./models/XGB_S1.json\")\n",
    "\n",
    "prediction_1 = xgb_reg_1.predict(R_1)\n",
    "\n",
    "xgb_reg_2 = xgb.XGBRegressor()\n",
    "xgb_reg_2.load_model(\"./models/XGB_S2.json\")\n",
    "\n",
    "prediction_2 = xgb_reg_2.predict(R_2)\n",
    "\n",
    "xgb_reg_3 = xgb.XGBRegressor()\n",
    "xgb_reg_3.load_model(\"./models/XGB_S3.json\")\n",
    "\n",
    "prediction_3 = xgb_reg_3.predict(R_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_submission(prediction_1, prediction_2, prediction_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
