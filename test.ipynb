{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the notebook environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "import xgboost as xgb\n",
    "from utils import *\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/leaderboard_data.mat')\n",
    "ecog_1 = raw['leaderboard_ecog'][0][0]\n",
    "ecog_2 = raw['leaderboard_ecog'][1][0]\n",
    "ecog_3 = raw['leaderboard_ecog'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/raw_training_data.mat')\n",
    "data_glove_1 = raw['train_dg'][0][0]\n",
    "data_glove_1_train = np.delete(data_glove_1, 3, 1)\n",
    "data_glove_2 = raw['train_dg'][1][0]\n",
    "data_glove_2_train = np.delete(data_glove_2, 3, 1)\n",
    "data_glove_3 = raw['train_dg'][2][0]\n",
    "data_glove_3_train = np.delete(data_glove_3, 3, 1)\n",
    "\n",
    "ecog_1_train = raw['train_ecog'][0][0]\n",
    "ecog_2_train = raw['train_ecog'][1][0]\n",
    "ecog_3_train = raw['train_ecog'][2][0]\n",
    "\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub1_comp.mat')\n",
    "ecog_1_comp = raw['train_data']\n",
    "dg_1_comp = raw['train_dg']\n",
    "ecog_1_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub2_comp.mat')\n",
    "ecog_2_comp = raw['train_data']\n",
    "dg_2_comp = raw['train_dg']\n",
    "ecog_2_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub3_comp.mat')\n",
    "ecog_3_comp = raw['train_data']\n",
    "dg_3_comp = raw['train_dg']\n",
    "ecog_3_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "dg_1_raw = scipy.io.loadmat('./datasets/sub1_testlabels.mat')\n",
    "dg_1_valid = dg_1_raw['test_dg'][50000:200000]\n",
    "dg_1_valid = np.delete(dg_1_valid, 3, 1)\n",
    "\n",
    "dg_2_raw = scipy.io.loadmat('./datasets/sub2_testlabels.mat')\n",
    "dg_2_valid = dg_2_raw['test_dg'][50000:200000]\n",
    "dg_2_valid = np.delete(dg_2_valid, 3, 1)\n",
    "\n",
    "dg_3_raw = scipy.io.loadmat('./datasets/sub3_testlabels.mat')\n",
    "dg_3_valid = dg_3_raw['test_dg'][50000:200000]\n",
    "dg_3_valid = np.delete(dg_3_valid, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_2_comp.shape[0] - 49000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 62, using nperseg = 62\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "NumWins(ecog_1, 1000, winLen, winDisp)\n",
    "\n",
    "feature_1 = get_windowed_feats(ecog_1, 1000, winLen, winOverlap)\n",
    "# y_1 = sig.resample(dg_1_valid, feature_1.shape[0], axis=0)\n",
    "feature_2 = get_windowed_feats(ecog_2, 1000, winLen, winOverlap)\n",
    "# y_2 = sig.resample(dg_2_valid, feature_2.shape[0], axis=0)\n",
    "feature_3 = get_windowed_feats(ecog_3, 1000, winLen, winOverlap)\n",
    "# y_3 = sig.resample(dg_3_valid, feature_3.shape[0], axis=0)\n",
    "\n",
    "idx_1 = np.load('./models/idx_S1.npy')\n",
    "idx_2 = np.load('./models/idx_S2.npy')\n",
    "idx_3 = np.load('./models/idx_S3.npy')\n",
    "\n",
    "R_1 = create_R_matrix(feature_1, 20)[:, idx_1]\n",
    "R_2 = create_R_matrix(feature_2, 20)[:, idx_2]\n",
    "R_3 = create_R_matrix(feature_3, 20)[:, idx_3]\n",
    "\n",
    "R_list = [R_1, R_2, R_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_S1 = np.load('./models/train_mean_S1.npy')\n",
    "train_std_S1 = np.load('./models/train_std_S1.npy')\n",
    "\n",
    "train_mean_S2 = np.load('./models/train_mean_S2.npy')\n",
    "train_std_S2 = np.load('./models/train_std_S2.npy')\n",
    "\n",
    "train_mean_S3 = np.load('./models/train_mean_S3.npy')\n",
    "train_std_S3 = np.load('./models/train_std_S3.npy')\n",
    "\n",
    "train_mean_ls = [train_mean_S1, train_mean_S2, train_mean_S3]\n",
    "train_std_ls = [train_std_S1, train_std_S2, train_std_S3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean_S2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x16864c490>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "lightgbm.Booster(model_file=f'./models/lgbr_f{0}_S{1}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(3):\n",
    "    # Load XGB\n",
    "    xgb_reg = xgb.XGBRegressor()\n",
    "    xgb_reg.load_model(f\"./models/XGB_S{i + 1}.json\")\n",
    "\n",
    "    prediction_xgb = xgb_reg.predict(R_list[i])\n",
    "    \n",
    "    # Load LGBM\n",
    "    lgbm_reg_list = [lightgbm.Booster(model_file=f'./models/lgbr_f{j}_S{i + 1}.txt') for j in range(4)]\n",
    "    \n",
    "    prediction_lgbm_list = [lgbm_reg.predict(R_list[i]) for lgbm_reg in lgbm_reg_list]\n",
    "    prediction_lgbm = np.vstack(prediction_lgbm_list).T\n",
    "    \n",
    "#     Load NN\n",
    "    leaderboard_dataset = FingerFeatureDataset((R_list[i] - train_mean_ls[i]) / train_std_ls[i], np.zeros(R_list[i].shape[0]).copy())\n",
    "    dataloader = DataLoader(leaderboard_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    net = FingerRegressor(R_list[i].shape[1], 4).to(device)\n",
    "    net.load_state_dict(torch.load(f'./models/NN_S{i + 1}.pth', map_location=device))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = []\n",
    "        net.eval()\n",
    "        for i, (ecog, dg) in enumerate(dataloader):\n",
    "            ecog = ecog.to(device)\n",
    "            dg = dg.to(device)\n",
    "            output = net(ecog).to(device)\n",
    "            pred += [output.detach().cpu().numpy()]\n",
    "\n",
    "    prediction_NN = np.concatenate(pred)\n",
    "    \n",
    "    \n",
    "    prediction = (prediction_lgbm + prediction_NN) / 2\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, ecog_1_valid.shape[0] / 1000, 1 / 1000)\n",
    "sample_time = np.linspace(0, ecog_1_valid.shape[0] / 1000, R_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(prediction, time, sample_time):\n",
    "    f = scipy.interpolate.PchipInterpolator(sample_time, prediction, axis=0)\n",
    "    \n",
    "    return f(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = post_processing(predictions[0], time, sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_submission(predictions, 'leaderboard_prediction.mat', 'predicted_dg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scipy.io.loadmat('validation.mat')['predicted_dg']\n",
    "prediction1 = predictions[0][0][:, [0,1,2,4]]\n",
    "prediction2 = predictions[1][0][:, [0,1,2,4]]\n",
    "prediction3 = predictions[2][0][:, [0,1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7043342848982502,\n",
       "  0.7780286682428237,\n",
       "  0.40574151900328004,\n",
       "  0.37020965463964267],\n",
       " 0.5645785316959991)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction1, dg_1_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6870996865295173,\n",
       "  0.5413679270892169,\n",
       "  0.3968677029448798,\n",
       "  0.4297641591775871],\n",
       " 0.5137748689353002)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction2, dg_2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8060932568774347,\n",
       "  0.7079927367497278,\n",
       "  0.6675050144705371,\n",
       "  0.7642086455448475],\n",
       " 0.7364499134106367)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction3, dg_3_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6049344380139786"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.5645785316959991 + 0.5137748689353002 + 0.7364499134106367) / 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
