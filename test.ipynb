{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the notebook environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "import xgboost as xgb\n",
    "from utils import *\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/leaderboard_data.mat')\n",
    "ecog_1 = raw['leaderboard_ecog'][0][0]\n",
    "ecog_2 = raw['leaderboard_ecog'][1][0]\n",
    "ecog_3 = raw['leaderboard_ecog'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/raw_training_data.mat')\n",
    "data_glove_1 = raw['train_dg'][0][0]\n",
    "data_glove_1_train = np.delete(data_glove_1, 3, 1)\n",
    "data_glove_2 = raw['train_dg'][1][0]\n",
    "data_glove_2_train = np.delete(data_glove_2, 3, 1)\n",
    "data_glove_3 = raw['train_dg'][2][0]\n",
    "data_glove_3_train = np.delete(data_glove_3, 3, 1)\n",
    "\n",
    "ecog_1_train = raw['train_ecog'][0][0]\n",
    "ecog_2_train = raw['train_ecog'][1][0]\n",
    "ecog_3_train = raw['train_ecog'][2][0]\n",
    "\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub1_comp.mat')\n",
    "ecog_1_comp = raw['train_data']\n",
    "dg_1_comp = raw['train_dg']\n",
    "ecog_1_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub2_comp.mat')\n",
    "ecog_2_comp = raw['train_data']\n",
    "dg_2_comp = raw['train_dg']\n",
    "ecog_2_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub3_comp.mat')\n",
    "ecog_3_comp = raw['train_data']\n",
    "dg_3_comp = raw['train_dg']\n",
    "ecog_3_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "dg_1_raw = scipy.io.loadmat('./datasets/sub1_testlabels.mat')\n",
    "dg_1_valid = dg_1_raw['test_dg'][50000:200000]\n",
    "dg_1_valid = np.delete(dg_1_valid, 3, 1)\n",
    "\n",
    "dg_2_raw = scipy.io.loadmat('./datasets/sub2_testlabels.mat')\n",
    "dg_2_valid = dg_2_raw['test_dg'][50000:200000]\n",
    "dg_2_valid = np.delete(dg_2_valid, 3, 1)\n",
    "\n",
    "dg_3_raw = scipy.io.loadmat('./datasets/sub3_testlabels.mat')\n",
    "dg_3_valid = dg_3_raw['test_dg'][50000:200000]\n",
    "dg_3_valid = np.delete(dg_3_valid, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_2_comp.shape[0] - 49000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "NumWins(ecog_1, 1000, winLen, winDisp)\n",
    "\n",
    "feature_1 = get_windowed_feats(ecog_1_valid, 1000, winLen, winOverlap)\n",
    "# y_1 = sig.resample(dg_1_valid, feature_1.shape[0], axis=0)\n",
    "feature_2 = get_windowed_feats(ecog_2_valid, 1000, winLen, winOverlap)\n",
    "# y_2 = sig.resample(dg_2_valid, feature_2.shape[0], axis=0)\n",
    "feature_3 = get_windowed_feats(ecog_3_valid, 1000, winLen, winOverlap)\n",
    "# y_3 = sig.resample(dg_3_valid, feature_3.shape[0], axis=0)\n",
    "\n",
    "idx_1 = np.load('./models/idx_S1.npy')\n",
    "idx_2 = np.load('./models/idx_S2.npy')\n",
    "idx_3 = np.load('./models/idx_S3.npy')\n",
    "\n",
    "R_1 = create_R_matrix(feature_1, 20)[:, idx_1]\n",
    "R_2 = create_R_matrix(feature_2, 20)[:, idx_2]\n",
    "R_3 = create_R_matrix(feature_3, 20)[:, idx_3]\n",
    "\n",
    "R_list = [R_1, R_2, R_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_S1 = np.load('./models/train_mean_S1.npy')\n",
    "train_std_S1 = np.load('./models/train_std_S1.npy')\n",
    "\n",
    "train_mean_S2 = np.load('./models/train_mean_S2.npy')\n",
    "train_std_S2 = np.load('./models/train_std_S2.npy')\n",
    "\n",
    "train_mean_S3 = np.load('./models/train_mean_S3.npy')\n",
    "train_std_S3 = np.load('./models/train_std_S3.npy')\n",
    "\n",
    "train_mean_ls = [train_mean_S1, train_mean_S2, train_mean_S3]\n",
    "train_std_ls = [train_std_S1, train_std_S2, train_std_S3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x165d90f90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "lightgbm.Booster(model_file=f'./models/lgbr_f{0}_S{1}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2999,617) (615,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     prediction_lgbm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(prediction_lgbm_list)\u001b[39m.\u001b[39mT\n\u001b[1;32m     15\u001b[0m \u001b[39m#     Load NN\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     leaderboard_dataset \u001b[39m=\u001b[39m FingerFeatureDataset((R_list[i] \u001b[39m-\u001b[39;49m train_mean_ls[i]) \u001b[39m/\u001b[39m train_std_ls[i], np\u001b[39m.\u001b[39mzeros(R_list[i]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m     17\u001b[0m     dataloader \u001b[39m=\u001b[39m DataLoader(leaderboard_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m     net \u001b[39m=\u001b[39m FingerRegressor(R_list[i]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2999,617) (615,) "
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(3):\n",
    "    # Load XGB\n",
    "    xgb_reg = xgb.XGBRegressor()\n",
    "    xgb_reg.load_model(f\"./models/XGB_S{i + 1}.json\")\n",
    "\n",
    "    prediction_xgb = xgb_reg.predict(R_list[i])\n",
    "    \n",
    "    # Load LGBM\n",
    "    lgbm_reg_list = [lightgbm.Booster(model_file=f'./models/lgbr_f{j}_S{i + 1}.txt') for j in range(4)]\n",
    "    \n",
    "    prediction_lgbm_list = [lgbm_reg.predict(R_list[i]) for lgbm_reg in lgbm_reg_list]\n",
    "    prediction_lgbm = np.vstack(prediction_lgbm_list).T\n",
    "    \n",
    "#     Load NN\n",
    "    leaderboard_dataset = FingerFeatureDataset((R_list[i] - train_mean_ls[i]) / train_std_ls[i], np.zeros(R_list[i].shape[0]).copy())\n",
    "    dataloader = DataLoader(leaderboard_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    net = FingerRegressor(R_list[i].shape[1], 4).to(device)\n",
    "    net.load_state_dict(torch.load(f'./models/NN_S{i + 1}.pth', map_location=device))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = []\n",
    "        net.eval()\n",
    "        for i, (ecog, dg) in enumerate(dataloader):\n",
    "            ecog = ecog.to(device)\n",
    "            dg = dg.to(device)\n",
    "            output = net(ecog).to(device)\n",
    "            pred += [output.detach().cpu().numpy()]\n",
    "\n",
    "    prediction_NN = np.concatenate(pred)\n",
    "    \n",
    "    \n",
    "    prediction = (prediction_lgbm + prediction_NN) / 2\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean_ls[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, ecog_1_valid.shape[0] / 1000, 1 / 1000)\n",
    "sample_time = np.linspace(0, ecog_1_valid.shape[0] / 1000, R_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(prediction, time, sample_time):\n",
    "    f = scipy.interpolate.PchipInterpolator(sample_time, prediction, axis=0)\n",
    "    \n",
    "    return f(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = post_processing(predictions[0], time, sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_submission(predictions, 'validation.mat', 'predicted_dg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scipy.io.loadmat('validation.mat')['predicted_dg']\n",
    "prediction1 = predictions[0][0][:, [0,1,2,4]]\n",
    "prediction2 = predictions[1][0][:, [0,1,2,4]]\n",
    "prediction3 = predictions[2][0][:, [0,1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6729982303315438,\n",
       "  0.7461896842564839,\n",
       "  0.3407088386454661,\n",
       "  0.40268559166145235],\n",
       " 0.5406455862237365)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction1, dg_1_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6805276336790187,\n",
       "  0.524321604336726,\n",
       "  0.3798516037347169,\n",
       "  0.4158781759899006],\n",
       " 0.5001447544350905)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction2, dg_2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8092553446980685,\n",
       "  0.7298080364494511,\n",
       "  0.6562946518234932,\n",
       "  0.7558823829933303],\n",
       " 0.7378101039910858)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction3, dg_3_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
