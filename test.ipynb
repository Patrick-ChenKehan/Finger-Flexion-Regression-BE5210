{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the notebook environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "import xgboost as xgb\n",
    "from utils import *\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/leaderboard_data.mat')\n",
    "ecog_1 = raw['leaderboard_ecog'][0][0]\n",
    "ecog_2 = raw['leaderboard_ecog'][1][0]\n",
    "ecog_3 = raw['leaderboard_ecog'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/raw_training_data.mat')\n",
    "data_glove_1 = raw['train_dg'][0][0]\n",
    "data_glove_1_train = np.delete(data_glove_1, 3, 1)\n",
    "data_glove_2 = raw['train_dg'][1][0]\n",
    "data_glove_2_train = np.delete(data_glove_2, 3, 1)\n",
    "data_glove_3 = raw['train_dg'][2][0]\n",
    "data_glove_3_train = np.delete(data_glove_3, 3, 1)\n",
    "\n",
    "ecog_1_train = raw['train_ecog'][0][0]\n",
    "ecog_2_train = raw['train_ecog'][1][0]\n",
    "ecog_3_train = raw['train_ecog'][2][0]\n",
    "\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub1_comp.mat')\n",
    "ecog_1_comp = raw['train_data']\n",
    "dg_1_comp = raw['train_dg']\n",
    "ecog_1_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub2_comp.mat')\n",
    "ecog_2_comp = raw['train_data']\n",
    "dg_2_comp = raw['train_dg']\n",
    "ecog_2_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub3_comp.mat')\n",
    "ecog_3_comp = raw['train_data']\n",
    "dg_3_comp = raw['train_dg']\n",
    "ecog_3_valid = raw['test_data'][50000:200000]\n",
    "\n",
    "dg_1_raw = scipy.io.loadmat('./datasets/sub1_testlabels.mat')\n",
    "dg_1_valid = dg_1_raw['test_dg'][50000:200000]\n",
    "dg_1_valid = np.delete(dg_1_valid, 3, 1)\n",
    "\n",
    "dg_2_raw = scipy.io.loadmat('./datasets/sub2_testlabels.mat')\n",
    "dg_2_valid = dg_2_raw['test_dg'][50000:200000]\n",
    "dg_2_valid = np.delete(dg_2_valid, 3, 1)\n",
    "\n",
    "dg_3_raw = scipy.io.loadmat('./datasets/sub3_testlabels.mat')\n",
    "dg_3_valid = dg_3_raw['test_dg'][50000:200000]\n",
    "dg_3_valid = np.delete(dg_3_valid, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_2_comp.shape[0] - 49000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 62, using nperseg = 62\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/lib/python3.11/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "NumWins(ecog_1, 1000, winLen, winDisp)\n",
    "\n",
    "feature_1 = get_windowed_feats(ecog_1_valid, 1000, winLen, winOverlap)\n",
    "# y_1 = sig.resample(dg_1_valid, feature_1.shape[0], axis=0)\n",
    "feature_2 = get_windowed_feats(ecog_2_valid, 1000, winLen, winOverlap)\n",
    "# y_2 = sig.resample(dg_2_valid, feature_2.shape[0], axis=0)\n",
    "feature_3 = get_windowed_feats(ecog_3_valid, 1000, winLen, winOverlap)\n",
    "# y_3 = sig.resample(dg_3_valid, feature_3.shape[0], axis=0)\n",
    "\n",
    "idx_1 = np.load('./models/idx_S1.npy')\n",
    "idx_2 = np.load('./models/idx_S2.npy')\n",
    "idx_3 = np.load('./models/idx_S3.npy')\n",
    "\n",
    "R_1 = create_R_matrix(feature_1, 20)[:, idx_1]\n",
    "R_2 = create_R_matrix(feature_2, 20)[:, idx_2]\n",
    "R_3 = create_R_matrix(feature_3, 20)[:, idx_3]\n",
    "\n",
    "R_list = [R_1, R_2, R_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_S1 = np.load('./models/train_mean_S1.npy')\n",
    "train_std_S1 = np.load('./models/train_std_S1.npy')\n",
    "\n",
    "train_mean_S2 = np.load('./models/train_mean_S2.npy')\n",
    "train_std_S2 = np.load('./models/train_std_S2.npy')\n",
    "\n",
    "train_mean_S3 = np.load('./models/train_mean_S3.npy')\n",
    "train_std_S3 = np.load('./models/train_std_S3.npy')\n",
    "\n",
    "train_mean_ls = [train_mean_S1, train_mean_S2, train_mean_S3]\n",
    "train_std_ls = [train_std_S1, train_std_S2, train_std_S3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x164d9b710>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "lightgbm.Booster(model_file=f'./models/lgbr_f{0}_S{1}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] The number of features in data (615) is not the same as it was in training data (617).\n",
      "You can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (615) is not the same as it was in training data (617).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Load LGBM\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     lgbm_reg_list \u001b[39m=\u001b[39m [lightgbm\u001b[39m.\u001b[39mBooster(model_file\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./models/lgbr_f\u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m_S\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[0;32m---> 12\u001b[0m     prediction_lgbm_list \u001b[39m=\u001b[39m [lgbm_reg\u001b[39m.\u001b[39;49mpredict(R_list[i]) \u001b[39mfor\u001b[39;49;00m lgbm_reg \u001b[39min\u001b[39;49;00m lgbm_reg_list]\n\u001b[1;32m     13\u001b[0m     prediction_lgbm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(prediction_lgbm_list)\u001b[39m.\u001b[39mT\n\u001b[1;32m     15\u001b[0m \u001b[39m#     Load NN\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Load LGBM\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     lgbm_reg_list \u001b[39m=\u001b[39m [lightgbm\u001b[39m.\u001b[39mBooster(model_file\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./models/lgbr_f\u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m_S\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[0;32m---> 12\u001b[0m     prediction_lgbm_list \u001b[39m=\u001b[39m [lgbm_reg\u001b[39m.\u001b[39;49mpredict(R_list[i]) \u001b[39mfor\u001b[39;00m lgbm_reg \u001b[39min\u001b[39;00m lgbm_reg_list]\n\u001b[1;32m     13\u001b[0m     prediction_lgbm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(prediction_lgbm_list)\u001b[39m.\u001b[39mT\n\u001b[1;32m     15\u001b[0m \u001b[39m#     Load NN\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/lightgbm/basic.py:4107\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   4105\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4106\u001b[0m         num_iteration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 4107\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   4108\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m   4109\u001b[0m     start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[1;32m   4110\u001b[0m     num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[1;32m   4111\u001b[0m     raw_score\u001b[39m=\u001b[39;49mraw_score,\n\u001b[1;32m   4112\u001b[0m     pred_leaf\u001b[39m=\u001b[39;49mpred_leaf,\n\u001b[1;32m   4113\u001b[0m     pred_contrib\u001b[39m=\u001b[39;49mpred_contrib,\n\u001b[1;32m   4114\u001b[0m     data_has_header\u001b[39m=\u001b[39;49mdata_has_header,\n\u001b[1;32m   4115\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features\n\u001b[1;32m   4116\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/lightgbm/basic.py:987\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m    980\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_csc(\n\u001b[1;32m    981\u001b[0m         csc\u001b[39m=\u001b[39mdata,\n\u001b[1;32m    982\u001b[0m         start_iteration\u001b[39m=\u001b[39mstart_iteration,\n\u001b[1;32m    983\u001b[0m         num_iteration\u001b[39m=\u001b[39mnum_iteration,\n\u001b[1;32m    984\u001b[0m         predict_type\u001b[39m=\u001b[39mpredict_type\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m--> 987\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pred_for_np2d(\n\u001b[1;32m    988\u001b[0m         mat\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    989\u001b[0m         start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[1;32m    990\u001b[0m         num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[1;32m    991\u001b[0m         predict_type\u001b[39m=\u001b[39;49mpredict_type\n\u001b[1;32m    992\u001b[0m     )\n\u001b[1;32m    993\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    994\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/lightgbm/basic.py:1127\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mreturn\u001b[39;00m preds, nrow\n\u001b[1;32m   1126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__inner_predict_np2d(\n\u001b[1;32m   1128\u001b[0m         mat\u001b[39m=\u001b[39;49mmat,\n\u001b[1;32m   1129\u001b[0m         start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[1;32m   1130\u001b[0m         num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[1;32m   1131\u001b[0m         predict_type\u001b[39m=\u001b[39;49mpredict_type,\n\u001b[1;32m   1132\u001b[0m         preds\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1133\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/lightgbm/basic.py:1080\u001b[0m, in \u001b[0;36m_InnerPredictor.__inner_predict_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length of pre-allocated predict array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1079\u001b[0m out_num_preds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int64(\u001b[39m0\u001b[39m)\n\u001b[0;32m-> 1080\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterPredictForMat(\n\u001b[1;32m   1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1082\u001b[0m     ptr_data,\n\u001b[1;32m   1083\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_ptr_data),\n\u001b[1;32m   1084\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m   1085\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m   1086\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(_C_API_IS_ROW_MAJOR),\n\u001b[1;32m   1087\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(predict_type),\n\u001b[1;32m   1088\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(start_iteration),\n\u001b[1;32m   1089\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(num_iteration),\n\u001b[1;32m   1090\u001b[0m     _c_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_parameter),\n\u001b[1;32m   1091\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_preds),\n\u001b[1;32m   1092\u001b[0m     preds\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(ctypes\u001b[39m.\u001b[39;49mPOINTER(ctypes\u001b[39m.\u001b[39;49mc_double))))\n\u001b[1;32m   1093\u001b[0m \u001b[39mif\u001b[39;00m n_preds \u001b[39m!=\u001b[39m out_num_preds\u001b[39m.\u001b[39mvalue:\n\u001b[1;32m   1094\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length for predict results\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/lightgbm/basic.py:233\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 233\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: The number of features in data (615) is not the same as it was in training data (617).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(3):\n",
    "    # Load XGB\n",
    "    xgb_reg = xgb.XGBRegressor()\n",
    "    xgb_reg.load_model(f\"./models/XGB_S{i + 1}.json\")\n",
    "\n",
    "    prediction_xgb = xgb_reg.predict(R_list[i])\n",
    "    \n",
    "    # Load LGBM\n",
    "    lgbm_reg_list = [lightgbm.Booster(model_file=f'./models/lgbr_f{j}_S{i + 1}.txt') for j in range(4)]\n",
    "    \n",
    "    prediction_lgbm_list = [lgbm_reg.predict(R_list[i]) for lgbm_reg in lgbm_reg_list]\n",
    "    prediction_lgbm = np.vstack(prediction_lgbm_list).T\n",
    "    \n",
    "#     Load NN\n",
    "    leaderboard_dataset = FingerFeatureDataset((R_list[i] - train_mean_ls[i]) / train_std_ls[i], np.zeros(R_list[i].shape[0]).copy())\n",
    "    dataloader = DataLoader(leaderboard_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    net = FingerRegressor(R_list[i].shape[1], 4).to(device)\n",
    "    net.load_state_dict(torch.load(f'./models/NN_S{i + 1}.pth', map_location=device))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = []\n",
    "        net.eval()\n",
    "        for i, (ecog, dg) in enumerate(dataloader):\n",
    "            ecog = ecog.to(device)\n",
    "            dg = dg.to(device)\n",
    "            output = net(ecog).to(device)\n",
    "            pred += [output.detach().cpu().numpy()]\n",
    "\n",
    "    prediction_NN = np.concatenate(pred)\n",
    "    \n",
    "    \n",
    "    prediction = (prediction_lgbm + prediction_NN) / 2\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, ecog_1_valid.shape[0] / 1000, 1 / 1000)\n",
    "sample_time = np.linspace(0, ecog_1_valid.shape[0] / 1000, R_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(prediction, time, sample_time):\n",
    "    f = scipy.interpolate.PchipInterpolator(sample_time, prediction, axis=0)\n",
    "    \n",
    "    return f(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = post_processing(predictions[0], time, sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_submission(predictions, 'validation.mat', 'predicted_dg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scipy.io.loadmat('validation.mat')['predicted_dg']\n",
    "prediction1 = predictions[0][0][:, [0,1,2,4]]\n",
    "prediction2 = predictions[1][0][:, [0,1,2,4]]\n",
    "prediction3 = predictions[2][0][:, [0,1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6729982303315438,\n",
       "  0.7461896842564839,\n",
       "  0.3407088386454661,\n",
       "  0.40268559166145235],\n",
       " 0.5406455862237365)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction1, dg_1_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6805276336790187,\n",
       "  0.524321604336726,\n",
       "  0.3798516037347169,\n",
       "  0.4158781759899006],\n",
       " 0.5001447544350905)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction2, dg_2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8092553446980685,\n",
       "  0.7298080364494511,\n",
       "  0.6562946518234932,\n",
       "  0.7558823829933303],\n",
       " 0.7378101039910858)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(prediction3, dg_3_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
