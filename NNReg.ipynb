{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.signal as sig\n",
    "from scipy.stats import pearsonr\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(0)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = scipy.io.loadmat('./datasets/raw_training_data.mat')\n",
    "data_glove_1 = raw['train_dg'][0][0]\n",
    "data_glove_1_train = np.delete(data_glove_1, 3, 1)\n",
    "data_glove_2 = raw['train_dg'][1][0]\n",
    "data_glove_2_train = np.delete(data_glove_2, 3, 1)\n",
    "data_glove_3 = raw['train_dg'][2][0]\n",
    "data_glove_3_train = np.delete(data_glove_3, 3, 1)\n",
    "\n",
    "ecog_1_train = raw['train_ecog'][0][0]\n",
    "ecog_2_train = raw['train_ecog'][1][0]\n",
    "ecog_3_train = raw['train_ecog'][2][0]\n",
    "\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub1_comp.mat')\n",
    "ecog_1_comp = raw['train_data']\n",
    "dg_1_comp = raw['train_dg']\n",
    "ecog_1_valid = raw['test_data'][49000:]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub2_comp.mat')\n",
    "ecog_2_comp = raw['train_data']\n",
    "dg_2_comp = raw['train_dg']\n",
    "ecog_2_valid = raw['test_data'][49000:]\n",
    "\n",
    "raw = scipy.io.loadmat('./datasets/sub3_comp.mat')\n",
    "ecog_3_comp = raw['train_data']\n",
    "dg_3_comp = raw['train_dg']\n",
    "ecog_3_valid = raw['test_data'][49000:]\n",
    "\n",
    "dg_1_raw = scipy.io.loadmat('./datasets/sub1_testlabels.mat')\n",
    "dg_1_valid = dg_1_raw['test_dg'][49000:]\n",
    "dg_1_valid = np.delete(dg_1_valid, 3, 1)\n",
    "\n",
    "dg_2_raw = scipy.io.loadmat('./datasets/sub2_testlabels.mat')\n",
    "dg_2_valid = dg_2_raw['test_dg'][49000:]\n",
    "dg_2_valid = np.delete(dg_2_valid, 3, 1)\n",
    "\n",
    "dg_3_raw = scipy.io.loadmat('./datasets/sub3_testlabels.mat')\n",
    "dg_3_valid = dg_3_raw['test_dg'][49000:]\n",
    "dg_3_valid = np.delete(dg_3_valid, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerFeatureDataset(Dataset):\n",
    "    def __init__(self, R, dg, window=2000):\n",
    "        self.R = np.float32(R + np.random.normal(0,0.1, R.shape))\n",
    "#         self.R = (self.R - ecog_1_train.mean(axis=0)) / ecog_1_train.std(axis=0)\n",
    "#         self.ecog = self.ecog.reshape(self.ecog.shape[0], 1, -1)\n",
    "        self.dg = np.float32(dg)\n",
    "        \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.R[idx], self.dg[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, winLen, winDisp):\n",
    "    result = []\n",
    "    for i in range(NumWins(x, 1000, winLen, winDisp)):\n",
    "        result.append(x[i * int(winDisp * 1000):i * int(winDisp * 1000) + int(winLen * 1000)].mean(axis=0))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 62, using nperseg = 62\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_1_train, 1000, winLen, winOverlap)\n",
    "# R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_1_valid, 1000, winLen, winOverlap)\n",
    "# R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_1_train\n",
    "Y_test = dg_1_valid\n",
    "Y_train = moving_average(Y_train, winLen, winDisp)\n",
    "Y_test = moving_average(Y_test, winLen, winDisp)\n",
    "\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "idx_1 = feature_selection(R_train, Y_train, 800)\n",
    "print(idx_1.shape)\n",
    "\n",
    "R_train = R_train[:, idx_1]\n",
    "train_mean_S1 = R_train.mean(axis=0)\n",
    "train_std_S1 = R_train.std(axis=0)\n",
    "R_train = (R_train - train_mean_S1) / train_std_S1\n",
    "R_test = R_test[:, idx_1]\n",
    "R_test = (R_test - train_mean_S1) / train_std_S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3019, 4)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_s1_train = FingerFeatureDataset(R_train.copy(), Y_train.copy())\n",
    "dataset_s1_valid = FingerFeatureDataset(R_test.copy(), Y_test.copy())\n",
    "\n",
    "train_loader = DataLoader(dataset_s1_train, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(dataset_s1_valid, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerRegressor(nn.Module):\n",
    "    def __init__(self, num_features, num_fingers) -> None:\n",
    "        super(FingerRegressor, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_features, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, num_fingers)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        output = self.fc3(x)\n",
    "\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 0.956 | Train Cor: 0.126 | Valid loss: 0.834 | Valid Cor: 0.3210514290333368\n",
      "Epoch 2 | Train loss: 0.822 | Train Cor: 0.252 | Valid loss: 0.786 | Valid Cor: 0.38774727770355133\n",
      "Epoch 3 | Train loss: 0.786 | Train Cor: 0.309 | Valid loss: 0.770 | Valid Cor: 0.4068624623698763\n",
      "Epoch 4 | Train loss: 0.759 | Train Cor: 0.357 | Valid loss: 0.758 | Valid Cor: 0.4257365376608523\n",
      "Epoch 5 | Train loss: 0.723 | Train Cor: 0.414 | Valid loss: 0.711 | Valid Cor: 0.4888074683380962\n",
      "Epoch 6 | Train loss: 0.682 | Train Cor: 0.462 | Valid loss: 0.687 | Valid Cor: 0.5310527078474977\n",
      "Epoch 7 | Train loss: 0.652 | Train Cor: 0.498 | Valid loss: 0.685 | Valid Cor: 0.5403597985162056\n",
      "Epoch 8 | Train loss: 0.613 | Train Cor: 0.537 | Valid loss: 0.690 | Valid Cor: 0.5433231932209281\n",
      "Epoch 9 | Train loss: 0.588 | Train Cor: 0.563 | Valid loss: 0.691 | Valid Cor: 0.5503782335356969\n",
      "Epoch 10 | Train loss: 0.567 | Train Cor: 0.578 | Valid loss: 0.699 | Valid Cor: 0.5574174548115609\n",
      "Epoch 11 | Train loss: 0.560 | Train Cor: 0.588 | Valid loss: 0.689 | Valid Cor: 0.5590650014483016\n",
      "Epoch 12 | Train loss: 0.549 | Train Cor: 0.598 | Valid loss: 0.708 | Valid Cor: 0.5491474307405029\n",
      "Epoch 13 | Train loss: 0.534 | Train Cor: 0.608 | Valid loss: 0.695 | Valid Cor: 0.5561087082826552\n",
      "Epoch 14 | Train loss: 0.521 | Train Cor: 0.620 | Valid loss: 0.708 | Valid Cor: 0.5458018021590259\n",
      "Epoch 15 | Train loss: 0.520 | Train Cor: 0.625 | Valid loss: 0.698 | Valid Cor: 0.553530345324211\n",
      "Epoch 16 | Train loss: 0.517 | Train Cor: 0.625 | Valid loss: 0.694 | Valid Cor: 0.5580872972229793\n",
      "Epoch 17 | Train loss: 0.502 | Train Cor: 0.640 | Valid loss: 0.693 | Valid Cor: 0.5599400576771116\n",
      "Epoch 18 | Train loss: 0.497 | Train Cor: 0.643 | Valid loss: 0.691 | Valid Cor: 0.5608082413724483\n",
      "Epoch 19 | Train loss: 0.501 | Train Cor: 0.641 | Valid loss: 0.684 | Valid Cor: 0.5720303566340242\n",
      "Epoch 20 | Train loss: 0.491 | Train Cor: 0.651 | Valid loss: 0.687 | Valid Cor: 0.5689638548363255\n",
      "Epoch 21 | Train loss: 0.489 | Train Cor: 0.651 | Valid loss: 0.694 | Valid Cor: 0.5652689358133015\n",
      "Epoch 22 | Train loss: 0.488 | Train Cor: 0.645 | Valid loss: 0.692 | Valid Cor: 0.5624122892270562\n",
      "Epoch 23 | Train loss: 0.493 | Train Cor: 0.646 | Valid loss: 0.688 | Valid Cor: 0.563195861504296\n",
      "Epoch 24 | Train loss: 0.488 | Train Cor: 0.652 | Valid loss: 0.689 | Valid Cor: 0.5580521844777877\n",
      "Epoch 25 | Train loss: 0.478 | Train Cor: 0.654 | Valid loss: 0.699 | Valid Cor: 0.5459877887576768\n",
      "Epoch 26 | Train loss: 0.486 | Train Cor: 0.651 | Valid loss: 0.694 | Valid Cor: 0.5532799773008419\n",
      "Epoch 27 | Train loss: 0.479 | Train Cor: 0.659 | Valid loss: 0.696 | Valid Cor: 0.5533218275453622\n",
      "Epoch 28 | Train loss: 0.474 | Train Cor: 0.660 | Valid loss: 0.680 | Valid Cor: 0.5644507704046169\n",
      "Epoch 29 | Train loss: 0.471 | Train Cor: 0.665 | Valid loss: 0.702 | Valid Cor: 0.5503375974362245\n",
      "Epoch 30 | Train loss: 0.457 | Train Cor: 0.673 | Valid loss: 0.685 | Valid Cor: 0.5678230159703558\n",
      "Epoch 31 | Train loss: 0.472 | Train Cor: 0.663 | Valid loss: 0.687 | Valid Cor: 0.5657539160053073\n",
      "Epoch 32 | Train loss: 0.472 | Train Cor: 0.660 | Valid loss: 0.685 | Valid Cor: 0.5668530589596021\n",
      "Epoch 33 | Train loss: 0.465 | Train Cor: 0.669 | Valid loss: 0.706 | Valid Cor: 0.5593425557070729\n",
      "Epoch 34 | Train loss: 0.462 | Train Cor: 0.667 | Valid loss: 0.697 | Valid Cor: 0.5581974011728402\n",
      "Epoch 35 | Train loss: 0.462 | Train Cor: 0.671 | Valid loss: 0.701 | Valid Cor: 0.5418606559178641\n"
     ]
    }
   ],
   "source": [
    "net = FingerRegressor(R_train.shape[1], 4).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    for (i, (ecog, dg)) in enumerate(train_loader):\n",
    "        # print(ecog.shape)\n",
    "        ecog = ecog.to(device)\n",
    "        dg = dg.to(device)\n",
    "        output = net(ecog)\n",
    "        pred += [output.detach().cpu().numpy()]\n",
    "        loss = criterion(output, dg)\n",
    "        # print (loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    train_cor = correlation_dl(sig.resample(pred, len(data_glove_1_train)), data_glove_1_train)[1]\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    # train_acc = correct / total\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pred = []\n",
    "        for (i, (ecog, dg)) in enumerate(test_loader):\n",
    "            ecog = ecog.to(device)\n",
    "            dg = dg.to(device)\n",
    "            output = net(ecog).to(device)\n",
    "            pred += [output.detach().cpu().numpy()]\n",
    "            loss = criterion(output, dg)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        pred = np.concatenate(pred)\n",
    "        val_cor = correlation_dl(sig.resample(pred, len(dg_1_valid)), dg_1_valid)[1]\n",
    "        \n",
    "        valid_loss = running_loss / len(test_loader)\n",
    "    # print(f'Epoch {epoch + 1} | Train loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Valid loss: {valid_loss:.3f} | Valid Acc: {val_cor}')\n",
    "    print(f'Epoch {epoch + 1} | Train loss: {train_loss:.3f} | Train Cor: {train_cor:.3f} | Valid loss: {valid_loss:.3f} | Valid Cor: {val_cor}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./models/train_mean_S1', train_mean_S1)\n",
    "np.save('./models/train_std_S1', train_std_S1)\n",
    "torch.save(net.state_dict(), './models/NN_S1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_2_train, 1000, winLen, winOverlap)\n",
    "# R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_2_valid, 1000, winLen, winOverlap)\n",
    "# R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_2_train\n",
    "Y_test = dg_2_valid\n",
    "Y_train = moving_average(Y_train, winLen, winDisp)\n",
    "Y_test = moving_average(Y_test, winLen, winDisp)\n",
    "# Y_train = sig.resample(Y_train, feature_train.shape[0], axis=0)\n",
    "# Y_test = sig.resample(Y_test, feature_test.shape[0], axis=0)\n",
    "\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "idx_2 = feature_selection(R_train, Y_train, 800)\n",
    "print(idx_2.shape)\n",
    "\n",
    "R_train = R_train[:, idx_2]\n",
    "train_mean_S2 = R_train.mean(axis=0)\n",
    "train_std_S2 = R_train.std(axis=0)\n",
    "R_train = (R_train - train_mean_S2) / train_std_S2\n",
    "R_test = R_test[:, idx_2]\n",
    "R_test = (R_test - train_mean_S2) / train_std_S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_s2_train = FingerFeatureDataset(R_train.copy(), Y_train.copy())\n",
    "dataset_s2_valid = FingerFeatureDataset(R_test.copy(), Y_test.copy())\n",
    "\n",
    "train_loader = DataLoader(dataset_s2_train, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(dataset_s2_valid, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 1.406 | Train Cor: 0.067 | Valid loss: 0.857 | Valid Cor: 0.10999424902461634\n",
      "Epoch 2 | Train loss: 0.930 | Train Cor: 0.116 | Valid loss: 0.840 | Valid Cor: 0.22931718917253366\n",
      "Epoch 3 | Train loss: 0.854 | Train Cor: 0.211 | Valid loss: 0.820 | Valid Cor: 0.27820038359262156\n",
      "Epoch 4 | Train loss: 0.819 | Train Cor: 0.264 | Valid loss: 0.800 | Valid Cor: 0.318585872717759\n",
      "Epoch 5 | Train loss: 0.791 | Train Cor: 0.313 | Valid loss: 0.779 | Valid Cor: 0.3570175457786615\n",
      "Epoch 6 | Train loss: 0.772 | Train Cor: 0.347 | Valid loss: 0.760 | Valid Cor: 0.39802852239557496\n",
      "Epoch 7 | Train loss: 0.740 | Train Cor: 0.390 | Valid loss: 0.734 | Valid Cor: 0.4182370203873644\n",
      "Epoch 8 | Train loss: 0.696 | Train Cor: 0.453 | Valid loss: 0.716 | Valid Cor: 0.4299283380680379\n",
      "Epoch 9 | Train loss: 0.664 | Train Cor: 0.490 | Valid loss: 0.709 | Valid Cor: 0.44443828313937417\n",
      "Epoch 10 | Train loss: 0.651 | Train Cor: 0.500 | Valid loss: 0.710 | Valid Cor: 0.45896537551883\n",
      "Epoch 11 | Train loss: 0.626 | Train Cor: 0.529 | Valid loss: 0.699 | Valid Cor: 0.4678876807334594\n",
      "Epoch 12 | Train loss: 0.604 | Train Cor: 0.553 | Valid loss: 0.693 | Valid Cor: 0.4700737135729862\n",
      "Epoch 13 | Train loss: 0.581 | Train Cor: 0.576 | Valid loss: 0.690 | Valid Cor: 0.4765288254159453\n",
      "Epoch 14 | Train loss: 0.575 | Train Cor: 0.577 | Valid loss: 0.697 | Valid Cor: 0.483632782743785\n",
      "Epoch 15 | Train loss: 0.565 | Train Cor: 0.586 | Valid loss: 0.684 | Valid Cor: 0.4836848148619998\n",
      "Epoch 16 | Train loss: 0.551 | Train Cor: 0.600 | Valid loss: 0.689 | Valid Cor: 0.4867129768041692\n",
      "Epoch 17 | Train loss: 0.551 | Train Cor: 0.605 | Valid loss: 0.686 | Valid Cor: 0.4952382648021967\n",
      "Epoch 18 | Train loss: 0.525 | Train Cor: 0.627 | Valid loss: 0.688 | Valid Cor: 0.4891211437556176\n",
      "Epoch 19 | Train loss: 0.538 | Train Cor: 0.618 | Valid loss: 0.675 | Valid Cor: 0.49645929536946465\n",
      "Epoch 20 | Train loss: 0.528 | Train Cor: 0.624 | Valid loss: 0.699 | Valid Cor: 0.49219288057890687\n",
      "Epoch 21 | Train loss: 0.517 | Train Cor: 0.635 | Valid loss: 0.694 | Valid Cor: 0.490327888896627\n",
      "Epoch 22 | Train loss: 0.527 | Train Cor: 0.624 | Valid loss: 0.689 | Valid Cor: 0.4992908983626114\n",
      "Epoch 23 | Train loss: 0.509 | Train Cor: 0.643 | Valid loss: 0.686 | Valid Cor: 0.5031830459695409\n",
      "Epoch 24 | Train loss: 0.500 | Train Cor: 0.645 | Valid loss: 0.678 | Valid Cor: 0.5023735397107285\n",
      "Epoch 25 | Train loss: 0.515 | Train Cor: 0.635 | Valid loss: 0.696 | Valid Cor: 0.5036688798154978\n",
      "Epoch 26 | Train loss: 0.508 | Train Cor: 0.639 | Valid loss: 0.685 | Valid Cor: 0.49607389374465105\n",
      "Epoch 27 | Train loss: 0.494 | Train Cor: 0.652 | Valid loss: 0.689 | Valid Cor: 0.49680327875549385\n",
      "Epoch 28 | Train loss: 0.498 | Train Cor: 0.650 | Valid loss: 0.689 | Valid Cor: 0.5023779550767451\n",
      "Epoch 29 | Train loss: 0.487 | Train Cor: 0.654 | Valid loss: 0.689 | Valid Cor: 0.5095117234922364\n",
      "Epoch 30 | Train loss: 0.497 | Train Cor: 0.652 | Valid loss: 0.697 | Valid Cor: 0.5048146645355414\n",
      "Epoch 31 | Train loss: 0.479 | Train Cor: 0.665 | Valid loss: 0.692 | Valid Cor: 0.5168972412708416\n",
      "Epoch 32 | Train loss: 0.470 | Train Cor: 0.669 | Valid loss: 0.686 | Valid Cor: 0.5006901409054861\n",
      "Epoch 33 | Train loss: 0.481 | Train Cor: 0.660 | Valid loss: 0.693 | Valid Cor: 0.506397707829796\n",
      "Epoch 34 | Train loss: 0.477 | Train Cor: 0.666 | Valid loss: 0.695 | Valid Cor: 0.49805967262136686\n",
      "Epoch 35 | Train loss: 0.467 | Train Cor: 0.672 | Valid loss: 0.682 | Valid Cor: 0.5114640989688589\n",
      "Epoch 36 | Train loss: 0.470 | Train Cor: 0.671 | Valid loss: 0.692 | Valid Cor: 0.5059516903162142\n",
      "Epoch 37 | Train loss: 0.465 | Train Cor: 0.678 | Valid loss: 0.700 | Valid Cor: 0.49657460578181967\n",
      "Epoch 38 | Train loss: 0.460 | Train Cor: 0.678 | Valid loss: 0.695 | Valid Cor: 0.5006021425471725\n",
      "Epoch 39 | Train loss: 0.474 | Train Cor: 0.670 | Valid loss: 0.688 | Valid Cor: 0.502306285725948\n",
      "Epoch 40 | Train loss: 0.457 | Train Cor: 0.680 | Valid loss: 0.688 | Valid Cor: 0.5090383425792379\n",
      "Epoch 41 | Train loss: 0.449 | Train Cor: 0.687 | Valid loss: 0.696 | Valid Cor: 0.49860558287112267\n",
      "Epoch 42 | Train loss: 0.461 | Train Cor: 0.675 | Valid loss: 0.708 | Valid Cor: 0.502560038087762\n",
      "Epoch 43 | Train loss: 0.442 | Train Cor: 0.691 | Valid loss: 0.696 | Valid Cor: 0.5044731703097944\n",
      "Epoch 44 | Train loss: 0.464 | Train Cor: 0.675 | Valid loss: 0.684 | Valid Cor: 0.5063427883201331\n",
      "Epoch 45 | Train loss: 0.455 | Train Cor: 0.680 | Valid loss: 0.693 | Valid Cor: 0.4982982753297307\n",
      "Epoch 46 | Train loss: 0.448 | Train Cor: 0.686 | Valid loss: 0.688 | Valid Cor: 0.508086217053552\n",
      "Epoch 47 | Train loss: 0.463 | Train Cor: 0.673 | Valid loss: 0.687 | Valid Cor: 0.5044084765204895\n",
      "Epoch 48 | Train loss: 0.446 | Train Cor: 0.685 | Valid loss: 0.686 | Valid Cor: 0.5026413136004336\n",
      "Epoch 49 | Train loss: 0.455 | Train Cor: 0.686 | Valid loss: 0.706 | Valid Cor: 0.4904137217796822\n",
      "Epoch 50 | Train loss: 0.444 | Train Cor: 0.686 | Valid loss: 0.688 | Valid Cor: 0.5014325202759153\n"
     ]
    }
   ],
   "source": [
    "net = FingerRegressor(R_train.shape[1], 4).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    for (i, (ecog, dg)) in enumerate(train_loader):\n",
    "        # print(ecog.shape)\n",
    "        ecog = ecog.to(device)\n",
    "        dg = dg.to(device)\n",
    "        output = net(ecog)\n",
    "        pred += [output.detach().cpu().numpy()]\n",
    "        loss = criterion(output, dg)\n",
    "        # print (loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    train_cor = correlation_dl(sig.resample(pred, len(data_glove_2_train)), data_glove_2_train)[1]\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    # train_acc = correct / total\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pred = []\n",
    "        for (i, (ecog, dg)) in enumerate(test_loader):\n",
    "            ecog = ecog.to(device)\n",
    "            dg = dg.to(device)\n",
    "            output = net(ecog).to(device)\n",
    "            pred += [output.detach().cpu().numpy()]\n",
    "            loss = criterion(output, dg)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        pred = np.concatenate(pred)\n",
    "        val_cor = correlation_dl(sig.resample(pred, len(dg_2_valid)), dg_2_valid)[1]\n",
    "        \n",
    "        valid_loss = running_loss / len(test_loader)\n",
    "    # print(f'Epoch {epoch + 1} | Train loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Valid loss: {valid_loss:.3f} | Valid Acc: {val_cor}')\n",
    "    print(f'Epoch {epoch + 1} | Train loss: {train_loss:.3f} | Train Cor: {train_cor:.3f} | Valid loss: {valid_loss:.3f} | Valid Cor: {val_cor}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./models/train_mean_S2', train_mean_S2)\n",
    "np.save('./models/train_std_S2', train_std_S2)\n",
    "torch.save(net.state_dict(), './models/NN_S2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(597,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: divide by zero encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:358: RuntimeWarning: invalid value encountered in divide\n",
      "  f_statistic = corr_coef_squared / (1 - corr_coef_squared) * deg_of_freedom\n"
     ]
    }
   ],
   "source": [
    "# Compute the R matrix for the training data\n",
    "feature_train = get_windowed_feats(ecog_3_train, 1000, winLen, winOverlap)\n",
    "# R_train = create_R_matrix(feature_train, 5)\n",
    "\n",
    "feature_test = get_windowed_feats(ecog_3_valid, 1000, winLen, winOverlap)\n",
    "# R_test = create_R_matrix(feature_test, 5)\n",
    "\n",
    "# Downsample the glove data\n",
    "Y_train = data_glove_3_train\n",
    "Y_test = dg_3_valid\n",
    "Y_train = moving_average(Y_train, winLen, winDisp)\n",
    "Y_test = moving_average(Y_test, winLen, winDisp)\n",
    "# Y_train = sig.resample(Y_train, feature_train.shape[0], axis=0)\n",
    "# Y_test = sig.resample(Y_test, feature_test.shape[0], axis=0)\n",
    "\n",
    "R_train = create_R_matrix(feature_train, 20)\n",
    "R_test = create_R_matrix(feature_test, 20)\n",
    "\n",
    "idx_3 = feature_selection(R_train, Y_train, 800)\n",
    "print(idx_3.shape)\n",
    "\n",
    "R_train = R_train[:, idx_3]\n",
    "train_mean_S3 = R_train.mean(axis=0)\n",
    "train_std_S3 = R_train.std(axis=0)\n",
    "R_train = (R_train - train_mean_S3) / train_std_S3\n",
    "R_test = R_test[:, idx_3]\n",
    "R_test = (R_test - train_mean_S3) / train_std_S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_s3_train = FingerFeatureDataset(R_train.copy(), Y_train.copy())\n",
    "dataset_s3_valid = FingerFeatureDataset(R_test.copy(), Y_test.copy())\n",
    "\n",
    "train_loader = DataLoader(dataset_s3_train, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(dataset_s3_valid, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 1.382 | Train Cor: 0.167 | Valid loss: 0.732 | Valid Cor: 0.43330096698478415\n",
      "Epoch 2 | Train loss: 0.762 | Train Cor: 0.382 | Valid loss: 0.641 | Valid Cor: 0.5442137449792854\n",
      "Epoch 3 | Train loss: 0.653 | Train Cor: 0.499 | Valid loss: 0.585 | Valid Cor: 0.6128858844131725\n",
      "Epoch 4 | Train loss: 0.600 | Train Cor: 0.550 | Valid loss: 0.554 | Valid Cor: 0.6398262418975164\n",
      "Epoch 5 | Train loss: 0.573 | Train Cor: 0.587 | Valid loss: 0.532 | Valid Cor: 0.6561748603064894\n",
      "Epoch 6 | Train loss: 0.542 | Train Cor: 0.617 | Valid loss: 0.511 | Valid Cor: 0.6810432826879983\n",
      "Epoch 7 | Train loss: 0.510 | Train Cor: 0.641 | Valid loss: 0.494 | Valid Cor: 0.684175062093592\n",
      "Epoch 8 | Train loss: 0.484 | Train Cor: 0.665 | Valid loss: 0.490 | Valid Cor: 0.6911981848142353\n",
      "Epoch 9 | Train loss: 0.473 | Train Cor: 0.677 | Valid loss: 0.474 | Valid Cor: 0.7049498837771777\n",
      "Epoch 10 | Train loss: 0.461 | Train Cor: 0.687 | Valid loss: 0.473 | Valid Cor: 0.7080266110873062\n",
      "Epoch 11 | Train loss: 0.443 | Train Cor: 0.701 | Valid loss: 0.465 | Valid Cor: 0.70966339724876\n",
      "Epoch 12 | Train loss: 0.429 | Train Cor: 0.712 | Valid loss: 0.476 | Valid Cor: 0.705808404765047\n",
      "Epoch 13 | Train loss: 0.431 | Train Cor: 0.712 | Valid loss: 0.464 | Valid Cor: 0.7131208373126885\n",
      "Epoch 14 | Train loss: 0.435 | Train Cor: 0.707 | Valid loss: 0.472 | Valid Cor: 0.7147612692597077\n",
      "Epoch 15 | Train loss: 0.417 | Train Cor: 0.723 | Valid loss: 0.461 | Valid Cor: 0.717240066809252\n",
      "Epoch 16 | Train loss: 0.422 | Train Cor: 0.719 | Valid loss: 0.464 | Valid Cor: 0.7159822130933988\n",
      "Epoch 17 | Train loss: 0.418 | Train Cor: 0.719 | Valid loss: 0.453 | Valid Cor: 0.7206216614607169\n",
      "Epoch 18 | Train loss: 0.402 | Train Cor: 0.733 | Valid loss: 0.464 | Valid Cor: 0.716410770416752\n",
      "Epoch 19 | Train loss: 0.414 | Train Cor: 0.723 | Valid loss: 0.451 | Valid Cor: 0.7216599300329735\n",
      "Epoch 20 | Train loss: 0.406 | Train Cor: 0.729 | Valid loss: 0.460 | Valid Cor: 0.7197755478968338\n",
      "Epoch 21 | Train loss: 0.392 | Train Cor: 0.738 | Valid loss: 0.467 | Valid Cor: 0.7144723931091688\n",
      "Epoch 22 | Train loss: 0.404 | Train Cor: 0.729 | Valid loss: 0.450 | Valid Cor: 0.7205554453172116\n",
      "Epoch 23 | Train loss: 0.396 | Train Cor: 0.735 | Valid loss: 0.453 | Valid Cor: 0.7184437672730832\n",
      "Epoch 24 | Train loss: 0.388 | Train Cor: 0.742 | Valid loss: 0.471 | Valid Cor: 0.7159277852110978\n",
      "Epoch 25 | Train loss: 0.393 | Train Cor: 0.735 | Valid loss: 0.464 | Valid Cor: 0.7121651451456902\n",
      "Epoch 26 | Train loss: 0.393 | Train Cor: 0.737 | Valid loss: 0.463 | Valid Cor: 0.7164237406576832\n",
      "Epoch 27 | Train loss: 0.383 | Train Cor: 0.741 | Valid loss: 0.457 | Valid Cor: 0.7147582654851079\n",
      "Epoch 28 | Train loss: 0.390 | Train Cor: 0.740 | Valid loss: 0.457 | Valid Cor: 0.7148525109268746\n",
      "Epoch 29 | Train loss: 0.385 | Train Cor: 0.741 | Valid loss: 0.451 | Valid Cor: 0.7199195119868453\n",
      "Epoch 30 | Train loss: 0.379 | Train Cor: 0.749 | Valid loss: 0.453 | Valid Cor: 0.7214111034520742\n",
      "Epoch 31 | Train loss: 0.373 | Train Cor: 0.751 | Valid loss: 0.459 | Valid Cor: 0.713572979038785\n",
      "Epoch 32 | Train loss: 0.370 | Train Cor: 0.752 | Valid loss: 0.455 | Valid Cor: 0.7212519638386902\n",
      "Epoch 33 | Train loss: 0.386 | Train Cor: 0.741 | Valid loss: 0.443 | Valid Cor: 0.7236760557396202\n",
      "Epoch 34 | Train loss: 0.371 | Train Cor: 0.754 | Valid loss: 0.459 | Valid Cor: 0.7188678057034388\n",
      "Epoch 35 | Train loss: 0.386 | Train Cor: 0.738 | Valid loss: 0.454 | Valid Cor: 0.718164585048911\n",
      "Epoch 36 | Train loss: 0.383 | Train Cor: 0.743 | Valid loss: 0.460 | Valid Cor: 0.7225048226713839\n",
      "Epoch 37 | Train loss: 0.379 | Train Cor: 0.744 | Valid loss: 0.460 | Valid Cor: 0.7185608840633502\n",
      "Epoch 38 | Train loss: 0.371 | Train Cor: 0.752 | Valid loss: 0.449 | Valid Cor: 0.7210247481538887\n",
      "Epoch 39 | Train loss: 0.367 | Train Cor: 0.755 | Valid loss: 0.462 | Valid Cor: 0.7180121406446112\n",
      "Epoch 40 | Train loss: 0.388 | Train Cor: 0.741 | Valid loss: 0.466 | Valid Cor: 0.7146496091587384\n",
      "Epoch 41 | Train loss: 0.358 | Train Cor: 0.760 | Valid loss: 0.453 | Valid Cor: 0.718303434050101\n",
      "Epoch 42 | Train loss: 0.364 | Train Cor: 0.758 | Valid loss: 0.442 | Valid Cor: 0.7246102711266382\n",
      "Epoch 43 | Train loss: 0.375 | Train Cor: 0.749 | Valid loss: 0.453 | Valid Cor: 0.7167658787973288\n",
      "Epoch 44 | Train loss: 0.377 | Train Cor: 0.748 | Valid loss: 0.447 | Valid Cor: 0.7187112512563649\n",
      "Epoch 45 | Train loss: 0.367 | Train Cor: 0.757 | Valid loss: 0.463 | Valid Cor: 0.7169619676998003\n",
      "Epoch 46 | Train loss: 0.359 | Train Cor: 0.761 | Valid loss: 0.457 | Valid Cor: 0.7151345550244914\n",
      "Epoch 47 | Train loss: 0.364 | Train Cor: 0.757 | Valid loss: 0.458 | Valid Cor: 0.716920096918627\n",
      "Epoch 48 | Train loss: 0.366 | Train Cor: 0.756 | Valid loss: 0.449 | Valid Cor: 0.7230853302977961\n",
      "Epoch 49 | Train loss: 0.363 | Train Cor: 0.758 | Valid loss: 0.451 | Valid Cor: 0.7181452814683201\n",
      "Epoch 50 | Train loss: 0.359 | Train Cor: 0.762 | Valid loss: 0.452 | Valid Cor: 0.721814974213093\n"
     ]
    }
   ],
   "source": [
    "# net = EEGNet().to(device)\n",
    "# net = EEGNetRegressor(4).to(device)\n",
    "# net = EEGNet(n_classes=4, channels=62, samples=3000).to(device) #.cuda(0)\n",
    "net = FingerRegressor(R_train.shape[1], 4).to(device)\n",
    "#print (net.forward(Variable(torch.Tensor(np.random.rand(1, 1, 120, 64)))))#.cuda(0))))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    for (i, (ecog, dg)) in enumerate(train_loader):\n",
    "        # print(ecog.shape)\n",
    "        ecog = ecog.to(device)\n",
    "        dg = dg.to(device)\n",
    "        output = net(ecog)\n",
    "        pred += [output.detach().cpu().numpy()]\n",
    "        loss = criterion(output, dg)\n",
    "        # print (loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    train_cor = correlation_dl(sig.resample(pred, len(data_glove_3_train)), data_glove_3_train)[1]\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    # train_acc = correct / total\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pred = []\n",
    "        for (i, (ecog, dg)) in enumerate(test_loader):\n",
    "            ecog = ecog.to(device)\n",
    "            dg = dg.to(device)\n",
    "            output = net(ecog).to(device)\n",
    "            pred += [output.detach().cpu().numpy()]\n",
    "            loss = criterion(output, dg)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        pred = np.concatenate(pred)\n",
    "        val_cor = correlation_dl(sig.resample(pred, len(dg_3_valid)), dg_3_valid)[1]\n",
    "        \n",
    "        valid_loss = running_loss / len(test_loader)\n",
    "    # print(f'Epoch {epoch + 1} | Train loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Valid loss: {valid_loss:.3f} | Valid Acc: {val_cor}')\n",
    "    print(f'Epoch {epoch + 1} | Train loss: {train_loss:.3f} | Train Cor: {train_cor:.3f} | Valid loss: {valid_loss:.3f} | Valid Cor: {val_cor}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./models/train_mean_S3', train_mean_S3)\n",
    "np.save('./models/train_std_S3', train_std_S3)\n",
    "torch.save(net.state_dict(), './models/NN_S3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 62, using nperseg = 62\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 48, using nperseg = 48\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:2014: UserWarning: nperseg = 256 is greater than input length  = 64, using nperseg = 64\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "ecog_1_leaderboard = ecog_1_comp[500: 500 + 147500]\n",
    "dg_1_leaderboard = dg_1_comp[500: 500 + 147500]\n",
    "\n",
    "ecog_2_leaderboard = ecog_2_comp[500: 500 + 147500]\n",
    "dg_2_leaderboard = dg_2_comp[500: 500 + 147500]\n",
    "\n",
    "ecog_3_leaderboard = ecog_3_comp[500: 500 + 147500]\n",
    "dg_3_leaderboard = dg_3_comp[500: 500 + 147500]\n",
    "\n",
    "winLen = 100 / 1e3\n",
    "winOverlap = 50 / 1e3\n",
    "winDisp = winLen - winOverlap\n",
    "\n",
    "\n",
    "feature_1 = get_windowed_feats(ecog_1_leaderboard, 1000, winLen, winOverlap)\n",
    "# R_1 = create_R_matrix(feature_1, 5)\n",
    "feature_2 = get_windowed_feats(ecog_2_leaderboard, 1000, winLen, winOverlap)\n",
    "# R_2 = create_R_matrix(feature_2, 5)\n",
    "feature_3 = get_windowed_feats(ecog_3_leaderboard, 1000, winLen, winOverlap)\n",
    "# R_3 = create_R_matrix(feature_3, 5)\n",
    "\n",
    "# idx_1 = np.load('./models/idx_S1.npy')\n",
    "# idx_2 = np.load('./models/idx_S2.npy')\n",
    "# idx_3 = np.load('./models/idx_S3.npy')\n",
    "\n",
    "R_1 = create_R_matrix(feature_1, 20)[:, idx_1]\n",
    "R_2 = create_R_matrix(feature_2, 20)[:, idx_2]\n",
    "R_3 = create_R_matrix(feature_3, 20)[:, idx_3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_S1 = np.load('./models/train_mean_S1.npy')\n",
    "train_std_S1 = np.load('./models/train_std_S1.npy')\n",
    "\n",
    "train_mean_S2 = np.load('./models/train_mean_S2.npy')\n",
    "train_std_S2 = np.load('./models/train_std_S2.npy')\n",
    "\n",
    "train_mean_S3 = np.load('./models/train_mean_S3.npy')\n",
    "train_std_S3 = np.load('./models/train_std_S3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553528686861728"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_dataset = FingerFeatureDataset((R_1 - train_mean_S1) / train_std_S1, np.zeros(R_1.shape[0]).copy())\n",
    "dataloader = DataLoader(leaderboard_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "net = FingerRegressor(R_1.shape[1], 4).to(device)\n",
    "net.load_state_dict(torch.load('./models/NN_S1.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = []\n",
    "    net.eval()\n",
    "    for i, (ecog, dg) in enumerate(dataloader):\n",
    "        ecog = ecog.to(device)\n",
    "        dg = dg.to(device)\n",
    "        output = net(ecog).to(device)\n",
    "        pred += [output.detach().cpu().numpy()]\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "correlation_dl(sig.resample(pred, len(dg_1_leaderboard)), dg_1_leaderboard)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5654337122490332"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_dataset = FingerFeatureDataset((R_2 - train_mean_S2) / train_std_S2, np.zeros(R_2.shape[0]).copy())\n",
    "dataloader = DataLoader(leaderboard_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "net = FingerRegressor(R_2.shape[1], 4).to(device)\n",
    "net.load_state_dict(torch.load('./models/NN_S2.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = []\n",
    "    net.eval()\n",
    "    for i, (ecog, dg) in enumerate(dataloader):\n",
    "        ecog = ecog.to(device)\n",
    "        dg = dg.to(device)\n",
    "        output = net(ecog).to(device)\n",
    "        pred += [output.detach().cpu().numpy()]\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "correlation_dl(sig.resample(pred, len(dg_2_leaderboard)), dg_2_leaderboard)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6924273174017038"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_dataset = FingerFeatureDataset((R_3 - train_mean_S3) / train_std_S3, np.zeros(R_3.shape[0]).copy())\n",
    "dataloader = DataLoader(leaderboard_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "net = FingerRegressor(R_3.shape[1], 4).to(device)\n",
    "net.load_state_dict(torch.load('./models/NN_S3.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = []\n",
    "    net.eval()\n",
    "    for i, (ecog, dg) in enumerate(dataloader):\n",
    "        ecog = ecog.to(device)\n",
    "        dg = dg.to(device)\n",
    "        output = net(ecog).to(device)\n",
    "        pred += [output.detach().cpu().numpy()]\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "correlation_dl(sig.resample(pred, len(dg_3_leaderboard)), dg_3_leaderboard)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
